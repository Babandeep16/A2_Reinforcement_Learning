{
  "algo": "Q-Learning",
  "env_id": "Taxi-v3",
  "seed": 42,
  "episodes": 5000,
  "lr": 0.001,
  "gamma": 0.9,
  "eps_start": 0.1,
  "eps_end": 0.1,
  "eps_decay": 1.0,
  "notes": "Basic tabular Q-learning with epsilon-greedy.",
  "episode_logs": [
    {
      "episode": 1,
      "steps": 200,
      "reward": -470.0
    },
    {
      "episode": 2,
      "steps": 200,
      "reward": -587.0
    },
    {
      "episode": 3,
      "steps": 200,
      "reward": -524.0
    },
    {
      "episode": 4,
      "steps": 200,
      "reward": -425.0
    },
    {
      "episode": 5,
      "steps": 200,
      "reward": -569.0
    },
    {
      "episode": 6,
      "steps": 200,
      "reward": -551.0
    },
    {
      "episode": 7,
      "steps": 200,
      "reward": -515.0
    },
    {
      "episode": 8,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 9,
      "steps": 200,
      "reward": -398.0
    },
    {
      "episode": 10,
      "steps": 200,
      "reward": -407.0
    },
    {
      "episode": 11,
      "steps": 200,
      "reward": -470.0
    },
    {
      "episode": 12,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 13,
      "steps": 183,
      "reward": -324.0
    },
    {
      "episode": 14,
      "steps": 200,
      "reward": -587.0
    },
    {
      "episode": 15,
      "steps": 200,
      "reward": -560.0
    },
    {
      "episode": 16,
      "steps": 192,
      "reward": -486.0
    },
    {
      "episode": 17,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 18,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 19,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 20,
      "steps": 200,
      "reward": -506.0
    },
    {
      "episode": 21,
      "steps": 200,
      "reward": -560.0
    },
    {
      "episode": 22,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 23,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 24,
      "steps": 200,
      "reward": -425.0
    },
    {
      "episode": 25,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 26,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 27,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 28,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 29,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 30,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 31,
      "steps": 200,
      "reward": -515.0
    },
    {
      "episode": 32,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 33,
      "steps": 131,
      "reward": -137.0
    },
    {
      "episode": 34,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 35,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 36,
      "steps": 200,
      "reward": -389.0
    },
    {
      "episode": 37,
      "steps": 200,
      "reward": -605.0
    },
    {
      "episode": 38,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 39,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 40,
      "steps": 200,
      "reward": -587.0
    },
    {
      "episode": 41,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 42,
      "steps": 200,
      "reward": -425.0
    },
    {
      "episode": 43,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 44,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 45,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 46,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 47,
      "steps": 134,
      "reward": -221.0
    },
    {
      "episode": 48,
      "steps": 200,
      "reward": -425.0
    },
    {
      "episode": 49,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 50,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 51,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 52,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 53,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 54,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 55,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 56,
      "steps": 112,
      "reward": -226.0
    },
    {
      "episode": 57,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 58,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 59,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 60,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 61,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 62,
      "steps": 133,
      "reward": -139.0
    },
    {
      "episode": 63,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 64,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 65,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 66,
      "steps": 190,
      "reward": -331.0
    },
    {
      "episode": 67,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 68,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 69,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 70,
      "steps": 55,
      "reward": -61.0
    },
    {
      "episode": 71,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 72,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 73,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 74,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 75,
      "steps": 200,
      "reward": -389.0
    },
    {
      "episode": 76,
      "steps": 144,
      "reward": -177.0
    },
    {
      "episode": 77,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 78,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 79,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 80,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 81,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 82,
      "steps": 103,
      "reward": -118.0
    },
    {
      "episode": 83,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 84,
      "steps": 111,
      "reward": -135.0
    },
    {
      "episode": 85,
      "steps": 178,
      "reward": -247.0
    },
    {
      "episode": 86,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 87,
      "steps": 200,
      "reward": -380.0
    },
    {
      "episode": 88,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 89,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 90,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 91,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 92,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 93,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 94,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 95,
      "steps": 200,
      "reward": -389.0
    },
    {
      "episode": 96,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 97,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 98,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 99,
      "steps": 200,
      "reward": -398.0
    },
    {
      "episode": 100,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 101,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 102,
      "steps": 200,
      "reward": -434.0
    },
    {
      "episode": 103,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 104,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 105,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 106,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 107,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 108,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 109,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 110,
      "steps": 64,
      "reward": -79.0
    },
    {
      "episode": 111,
      "steps": 124,
      "reward": -139.0
    },
    {
      "episode": 112,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 113,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 114,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 115,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 116,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 117,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 118,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 119,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 120,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 121,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 122,
      "steps": 156,
      "reward": -216.0
    },
    {
      "episode": 123,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 124,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 125,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 126,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 127,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 128,
      "steps": 29,
      "reward": -17.0
    },
    {
      "episode": 129,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 130,
      "steps": 63,
      "reward": -60.0
    },
    {
      "episode": 131,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 132,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 133,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 134,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 135,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 136,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 137,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 138,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 139,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 140,
      "steps": 170,
      "reward": -203.0
    },
    {
      "episode": 141,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 142,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 143,
      "steps": 118,
      "reward": -187.0
    },
    {
      "episode": 144,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 145,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 146,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 147,
      "steps": 200,
      "reward": -407.0
    },
    {
      "episode": 148,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 149,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 150,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 151,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 152,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 153,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 154,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 155,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 156,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 157,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 158,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 159,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 160,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 161,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 162,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 163,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 164,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 165,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 166,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 167,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 168,
      "steps": 200,
      "reward": -389.0
    },
    {
      "episode": 169,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 170,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 171,
      "steps": 90,
      "reward": -78.0
    },
    {
      "episode": 172,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 173,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 174,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 175,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 176,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 177,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 178,
      "steps": 200,
      "reward": -389.0
    },
    {
      "episode": 179,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 180,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 181,
      "steps": 119,
      "reward": -134.0
    },
    {
      "episode": 182,
      "steps": 185,
      "reward": -272.0
    },
    {
      "episode": 183,
      "steps": 200,
      "reward": -425.0
    },
    {
      "episode": 184,
      "steps": 95,
      "reward": -101.0
    },
    {
      "episode": 185,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 186,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 187,
      "steps": 180,
      "reward": -195.0
    },
    {
      "episode": 188,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 189,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 190,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 191,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 192,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 193,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 194,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 195,
      "steps": 157,
      "reward": -181.0
    },
    {
      "episode": 196,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 197,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 198,
      "steps": 177,
      "reward": -192.0
    },
    {
      "episode": 199,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 200,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 201,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 202,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 203,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 204,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 205,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 206,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 207,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 208,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 209,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 210,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 211,
      "steps": 200,
      "reward": -371.0
    },
    {
      "episode": 212,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 213,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 214,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 215,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 216,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 217,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 218,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 219,
      "steps": 139,
      "reward": -127.0
    },
    {
      "episode": 220,
      "steps": 200,
      "reward": -380.0
    },
    {
      "episode": 221,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 222,
      "steps": 183,
      "reward": -207.0
    },
    {
      "episode": 223,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 224,
      "steps": 37,
      "reward": -25.0
    },
    {
      "episode": 225,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 226,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 227,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 228,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 229,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 230,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 231,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 232,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 233,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 234,
      "steps": 28,
      "reward": -16.0
    },
    {
      "episode": 235,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 236,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 237,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 238,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 239,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 240,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 241,
      "steps": 186,
      "reward": -201.0
    },
    {
      "episode": 242,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 243,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 244,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 245,
      "steps": 194,
      "reward": -281.0
    },
    {
      "episode": 246,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 247,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 248,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 249,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 250,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 251,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 252,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 253,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 254,
      "steps": 109,
      "reward": -142.0
    },
    {
      "episode": 255,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 256,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 257,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 258,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 259,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 260,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 261,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 262,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 263,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 264,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 265,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 266,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 267,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 268,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 269,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 270,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 271,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 272,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 273,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 274,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 275,
      "steps": 82,
      "reward": -124.0
    },
    {
      "episode": 276,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 277,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 278,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 279,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 280,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 281,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 282,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 283,
      "steps": 85,
      "reward": -100.0
    },
    {
      "episode": 284,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 285,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 286,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 287,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 288,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 289,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 290,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 291,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 292,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 293,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 294,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 295,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 296,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 297,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 298,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 299,
      "steps": 50,
      "reward": -38.0
    },
    {
      "episode": 300,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 301,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 302,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 303,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 304,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 305,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 306,
      "steps": 154,
      "reward": -169.0
    },
    {
      "episode": 307,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 308,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 309,
      "steps": 65,
      "reward": -71.0
    },
    {
      "episode": 310,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 311,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 312,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 313,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 314,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 315,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 316,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 317,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 318,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 319,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 320,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 321,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 322,
      "steps": 39,
      "reward": -18.0
    },
    {
      "episode": 323,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 324,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 325,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 326,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 327,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 328,
      "steps": 135,
      "reward": -141.0
    },
    {
      "episode": 329,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 330,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 331,
      "steps": 182,
      "reward": -215.0
    },
    {
      "episode": 332,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 333,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 334,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 335,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 336,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 337,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 338,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 339,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 340,
      "steps": 88,
      "reward": -103.0
    },
    {
      "episode": 341,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 342,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 343,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 344,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 345,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 346,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 347,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 348,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 349,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 350,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 351,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 352,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 353,
      "steps": 135,
      "reward": -204.0
    },
    {
      "episode": 354,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 355,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 356,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 357,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 358,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 359,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 360,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 361,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 362,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 363,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 364,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 365,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 366,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 367,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 368,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 369,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 370,
      "steps": 145,
      "reward": -232.0
    },
    {
      "episode": 371,
      "steps": 109,
      "reward": -97.0
    },
    {
      "episode": 372,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 373,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 374,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 375,
      "steps": 171,
      "reward": -222.0
    },
    {
      "episode": 376,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 377,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 378,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 379,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 380,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 381,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 382,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 383,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 384,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 385,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 386,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 387,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 388,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 389,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 390,
      "steps": 42,
      "reward": -21.0
    },
    {
      "episode": 391,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 392,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 393,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 394,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 395,
      "steps": 177,
      "reward": -201.0
    },
    {
      "episode": 396,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 397,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 398,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 399,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 400,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 401,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 402,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 403,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 404,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 405,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 406,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 407,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 408,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 409,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 410,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 411,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 412,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 413,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 414,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 415,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 416,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 417,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 418,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 419,
      "steps": 68,
      "reward": -92.0
    },
    {
      "episode": 420,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 421,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 422,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 423,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 424,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 425,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 426,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 427,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 428,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 429,
      "steps": 100,
      "reward": -97.0
    },
    {
      "episode": 430,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 431,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 432,
      "steps": 137,
      "reward": -188.0
    },
    {
      "episode": 433,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 434,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 435,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 436,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 437,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 438,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 439,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 440,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 441,
      "steps": 126,
      "reward": -150.0
    },
    {
      "episode": 442,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 443,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 444,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 445,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 446,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 447,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 448,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 449,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 450,
      "steps": 162,
      "reward": -258.0
    },
    {
      "episode": 451,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 452,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 453,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 454,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 455,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 456,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 457,
      "steps": 45,
      "reward": -42.0
    },
    {
      "episode": 458,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 459,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 460,
      "steps": 38,
      "reward": -26.0
    },
    {
      "episode": 461,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 462,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 463,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 464,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 465,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 466,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 467,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 468,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 469,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 470,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 471,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 472,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 473,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 474,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 475,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 476,
      "steps": 101,
      "reward": -143.0
    },
    {
      "episode": 477,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 478,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 479,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 480,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 481,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 482,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 483,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 484,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 485,
      "steps": 179,
      "reward": -230.0
    },
    {
      "episode": 486,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 487,
      "steps": 100,
      "reward": -124.0
    },
    {
      "episode": 488,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 489,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 490,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 491,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 492,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 493,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 494,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 495,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 496,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 497,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 498,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 499,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 500,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 501,
      "steps": 167,
      "reward": -191.0
    },
    {
      "episode": 502,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 503,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 504,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 505,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 506,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 507,
      "steps": 65,
      "reward": -71.0
    },
    {
      "episode": 508,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 509,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 510,
      "steps": 32,
      "reward": -20.0
    },
    {
      "episode": 511,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 512,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 513,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 514,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 515,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 516,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 517,
      "steps": 190,
      "reward": -223.0
    },
    {
      "episode": 518,
      "steps": 115,
      "reward": -130.0
    },
    {
      "episode": 519,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 520,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 521,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 522,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 523,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 524,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 525,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 526,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 527,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 528,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 529,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 530,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 531,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 532,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 533,
      "steps": 200,
      "reward": -371.0
    },
    {
      "episode": 534,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 535,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 536,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 537,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 538,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 539,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 540,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 541,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 542,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 543,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 544,
      "steps": 200,
      "reward": -371.0
    },
    {
      "episode": 545,
      "steps": 44,
      "reward": -32.0
    },
    {
      "episode": 546,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 547,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 548,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 549,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 550,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 551,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 552,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 553,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 554,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 555,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 556,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 557,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 558,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 559,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 560,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 561,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 562,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 563,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 564,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 565,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 566,
      "steps": 32,
      "reward": -29.0
    },
    {
      "episode": 567,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 568,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 569,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 570,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 571,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 572,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 573,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 574,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 575,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 576,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 577,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 578,
      "steps": 73,
      "reward": -106.0
    },
    {
      "episode": 579,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 580,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 581,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 582,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 583,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 584,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 585,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 586,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 587,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 588,
      "steps": 127,
      "reward": -169.0
    },
    {
      "episode": 589,
      "steps": 190,
      "reward": -214.0
    },
    {
      "episode": 590,
      "steps": 200,
      "reward": -389.0
    },
    {
      "episode": 591,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 592,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 593,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 594,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 595,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 596,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 597,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 598,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 599,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 600,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 601,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 602,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 603,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 604,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 605,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 606,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 607,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 608,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 609,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 610,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 611,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 612,
      "steps": 200,
      "reward": -380.0
    },
    {
      "episode": 613,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 614,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 615,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 616,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 617,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 618,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 619,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 620,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 621,
      "steps": 44,
      "reward": -41.0
    },
    {
      "episode": 622,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 623,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 624,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 625,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 626,
      "steps": 86,
      "reward": -128.0
    },
    {
      "episode": 627,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 628,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 629,
      "steps": 142,
      "reward": -193.0
    },
    {
      "episode": 630,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 631,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 632,
      "steps": 82,
      "reward": -79.0
    },
    {
      "episode": 633,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 634,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 635,
      "steps": 152,
      "reward": -176.0
    },
    {
      "episode": 636,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 637,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 638,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 639,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 640,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 641,
      "steps": 196,
      "reward": -274.0
    },
    {
      "episode": 642,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 643,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 644,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 645,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 646,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 647,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 648,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 649,
      "steps": 195,
      "reward": -255.0
    },
    {
      "episode": 650,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 651,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 652,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 653,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 654,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 655,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 656,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 657,
      "steps": 132,
      "reward": -228.0
    },
    {
      "episode": 658,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 659,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 660,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 661,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 662,
      "steps": 67,
      "reward": -64.0
    },
    {
      "episode": 663,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 664,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 665,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 666,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 667,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 668,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 669,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 670,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 671,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 672,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 673,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 674,
      "steps": 90,
      "reward": -105.0
    },
    {
      "episode": 675,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 676,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 677,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 678,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 679,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 680,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 681,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 682,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 683,
      "steps": 182,
      "reward": -215.0
    },
    {
      "episode": 684,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 685,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 686,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 687,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 688,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 689,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 690,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 691,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 692,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 693,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 694,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 695,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 696,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 697,
      "steps": 165,
      "reward": -198.0
    },
    {
      "episode": 698,
      "steps": 164,
      "reward": -188.0
    },
    {
      "episode": 699,
      "steps": 100,
      "reward": -142.0
    },
    {
      "episode": 700,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 701,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 702,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 703,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 704,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 705,
      "steps": 199,
      "reward": -304.0
    },
    {
      "episode": 706,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 707,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 708,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 709,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 710,
      "steps": 138,
      "reward": -144.0
    },
    {
      "episode": 711,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 712,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 713,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 714,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 715,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 716,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 717,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 718,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 719,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 720,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 721,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 722,
      "steps": 52,
      "reward": -58.0
    },
    {
      "episode": 723,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 724,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 725,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 726,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 727,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 728,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 729,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 730,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 731,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 732,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 733,
      "steps": 122,
      "reward": -164.0
    },
    {
      "episode": 734,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 735,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 736,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 737,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 738,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 739,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 740,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 741,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 742,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 743,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 744,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 745,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 746,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 747,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 748,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 749,
      "steps": 107,
      "reward": -167.0
    },
    {
      "episode": 750,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 751,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 752,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 753,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 754,
      "steps": 182,
      "reward": -197.0
    },
    {
      "episode": 755,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 756,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 757,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 758,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 759,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 760,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 761,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 762,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 763,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 764,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 765,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 766,
      "steps": 74,
      "reward": -98.0
    },
    {
      "episode": 767,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 768,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 769,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 770,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 771,
      "steps": 87,
      "reward": -75.0
    },
    {
      "episode": 772,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 773,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 774,
      "steps": 72,
      "reward": -87.0
    },
    {
      "episode": 775,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 776,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 777,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 778,
      "steps": 200,
      "reward": -251.0
    },
    {
      "episode": 779,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 780,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 781,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 782,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 783,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 784,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 785,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 786,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 787,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 788,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 789,
      "steps": 12,
      "reward": 0.0
    },
    {
      "episode": 790,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 791,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 792,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 793,
      "steps": 197,
      "reward": -221.0
    },
    {
      "episode": 794,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 795,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 796,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 797,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 798,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 799,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 800,
      "steps": 90,
      "reward": -114.0
    },
    {
      "episode": 801,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 802,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 803,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 804,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 805,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 806,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 807,
      "steps": 197,
      "reward": -284.0
    },
    {
      "episode": 808,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 809,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 810,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 811,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 812,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 813,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 814,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 815,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 816,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 817,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 818,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 819,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 820,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 821,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 822,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 823,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 824,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 825,
      "steps": 159,
      "reward": -183.0
    },
    {
      "episode": 826,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 827,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 828,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 829,
      "steps": 154,
      "reward": -214.0
    },
    {
      "episode": 830,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 831,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 832,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 833,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 834,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 835,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 836,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 837,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 838,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 839,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 840,
      "steps": 49,
      "reward": -64.0
    },
    {
      "episode": 841,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 842,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 843,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 844,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 845,
      "steps": 127,
      "reward": -133.0
    },
    {
      "episode": 846,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 847,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 848,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 849,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 850,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 851,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 852,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 853,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 854,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 855,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 856,
      "steps": 154,
      "reward": -205.0
    },
    {
      "episode": 857,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 858,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 859,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 860,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 861,
      "steps": 137,
      "reward": -161.0
    },
    {
      "episode": 862,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 863,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 864,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 865,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 866,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 867,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 868,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 869,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 870,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 871,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 872,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 873,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 874,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 875,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 876,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 877,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 878,
      "steps": 32,
      "reward": -29.0
    },
    {
      "episode": 879,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 880,
      "steps": 184,
      "reward": -280.0
    },
    {
      "episode": 881,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 882,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 883,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 884,
      "steps": 75,
      "reward": -81.0
    },
    {
      "episode": 885,
      "steps": 199,
      "reward": -259.0
    },
    {
      "episode": 886,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 887,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 888,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 889,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 890,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 891,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 892,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 893,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 894,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 895,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 896,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 897,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 898,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 899,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 900,
      "steps": 190,
      "reward": -241.0
    },
    {
      "episode": 901,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 902,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 903,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 904,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 905,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 906,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 907,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 908,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 909,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 910,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 911,
      "steps": 83,
      "reward": -107.0
    },
    {
      "episode": 912,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 913,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 914,
      "steps": 143,
      "reward": -167.0
    },
    {
      "episode": 915,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 916,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 917,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 918,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 919,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 920,
      "steps": 109,
      "reward": -142.0
    },
    {
      "episode": 921,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 922,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 923,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 924,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 925,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 926,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 927,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 928,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 929,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 930,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 931,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 932,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 933,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 934,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 935,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 936,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 937,
      "steps": 42,
      "reward": -21.0
    },
    {
      "episode": 938,
      "steps": 168,
      "reward": -183.0
    },
    {
      "episode": 939,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 940,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 941,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 942,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 943,
      "steps": 53,
      "reward": -50.0
    },
    {
      "episode": 944,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 945,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 946,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 947,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 948,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 949,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 950,
      "steps": 136,
      "reward": -160.0
    },
    {
      "episode": 951,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 952,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 953,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 954,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 955,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 956,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 957,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 958,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 959,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 960,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 961,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 962,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 963,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 964,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 965,
      "steps": 93,
      "reward": -108.0
    },
    {
      "episode": 966,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 967,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 968,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 969,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 970,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 971,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 972,
      "steps": 97,
      "reward": -130.0
    },
    {
      "episode": 973,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 974,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 975,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 976,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 977,
      "steps": 86,
      "reward": -101.0
    },
    {
      "episode": 978,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 979,
      "steps": 167,
      "reward": -209.0
    },
    {
      "episode": 980,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 981,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 982,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 983,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 984,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 985,
      "steps": 42,
      "reward": -39.0
    },
    {
      "episode": 986,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 987,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 988,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 989,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 990,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 991,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 992,
      "steps": 192,
      "reward": -225.0
    },
    {
      "episode": 993,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 994,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 995,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 996,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 997,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 998,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 999,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1000,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1001,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1002,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1003,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1004,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 1005,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1006,
      "steps": 33,
      "reward": -30.0
    },
    {
      "episode": 1007,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1008,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1009,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1010,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1011,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1012,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1013,
      "steps": 105,
      "reward": -129.0
    },
    {
      "episode": 1014,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1015,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1016,
      "steps": 131,
      "reward": -164.0
    },
    {
      "episode": 1017,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1018,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1019,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1020,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1021,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1022,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1023,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1024,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1025,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1026,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1027,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1028,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1029,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1030,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1031,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1032,
      "steps": 160,
      "reward": -202.0
    },
    {
      "episode": 1033,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1034,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1035,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1036,
      "steps": 142,
      "reward": -148.0
    },
    {
      "episode": 1037,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1038,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1039,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1040,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 1041,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1042,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1043,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1044,
      "steps": 120,
      "reward": -126.0
    },
    {
      "episode": 1045,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1046,
      "steps": 160,
      "reward": -238.0
    },
    {
      "episode": 1047,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1048,
      "steps": 49,
      "reward": -46.0
    },
    {
      "episode": 1049,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1050,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1051,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1052,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1053,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1054,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1055,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 1056,
      "steps": 140,
      "reward": -155.0
    },
    {
      "episode": 1057,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1058,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1059,
      "steps": 114,
      "reward": -174.0
    },
    {
      "episode": 1060,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1061,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1062,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1063,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1064,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1065,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1066,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1067,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1068,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1069,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1070,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1071,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1072,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 1073,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1074,
      "steps": 190,
      "reward": -250.0
    },
    {
      "episode": 1075,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1076,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1077,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1078,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1079,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1080,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1081,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1082,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1083,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1084,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1085,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1086,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1087,
      "steps": 91,
      "reward": -106.0
    },
    {
      "episode": 1088,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1089,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1090,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1091,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1092,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1093,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1094,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1095,
      "steps": 86,
      "reward": -101.0
    },
    {
      "episode": 1096,
      "steps": 183,
      "reward": -279.0
    },
    {
      "episode": 1097,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1098,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1099,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1100,
      "steps": 24,
      "reward": -12.0
    },
    {
      "episode": 1101,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1102,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1103,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1104,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1105,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1106,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1107,
      "steps": 160,
      "reward": -193.0
    },
    {
      "episode": 1108,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1109,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1110,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1111,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1112,
      "steps": 189,
      "reward": -222.0
    },
    {
      "episode": 1113,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1114,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1115,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1116,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1117,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1118,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 1119,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1120,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1121,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1122,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1123,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1124,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1125,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1126,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1127,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1128,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1129,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1130,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1131,
      "steps": 82,
      "reward": -115.0
    },
    {
      "episode": 1132,
      "steps": 80,
      "reward": -77.0
    },
    {
      "episode": 1133,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1134,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1135,
      "steps": 96,
      "reward": -111.0
    },
    {
      "episode": 1136,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1137,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1138,
      "steps": 15,
      "reward": -3.0
    },
    {
      "episode": 1139,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1140,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1141,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1142,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1143,
      "steps": 81,
      "reward": -69.0
    },
    {
      "episode": 1144,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1145,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1146,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1147,
      "steps": 146,
      "reward": -170.0
    },
    {
      "episode": 1148,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1149,
      "steps": 159,
      "reward": -192.0
    },
    {
      "episode": 1150,
      "steps": 177,
      "reward": -201.0
    },
    {
      "episode": 1151,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1152,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1153,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1154,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 1155,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1156,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1157,
      "steps": 197,
      "reward": -266.0
    },
    {
      "episode": 1158,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1159,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1160,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1161,
      "steps": 14,
      "reward": 7.0
    },
    {
      "episode": 1162,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1163,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1164,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 1165,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1166,
      "steps": 21,
      "reward": 0.0
    },
    {
      "episode": 1167,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1168,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1169,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1170,
      "steps": 196,
      "reward": -247.0
    },
    {
      "episode": 1171,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1172,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1173,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 1174,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1175,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 1176,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1177,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1178,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1179,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 1180,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1181,
      "steps": 56,
      "reward": -80.0
    },
    {
      "episode": 1182,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1183,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1184,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1185,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1186,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1187,
      "steps": 171,
      "reward": -240.0
    },
    {
      "episode": 1188,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1189,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1190,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1191,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 1192,
      "steps": 132,
      "reward": -138.0
    },
    {
      "episode": 1193,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1194,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1195,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1196,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1197,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1198,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1199,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1200,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1201,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1202,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1203,
      "steps": 92,
      "reward": -98.0
    },
    {
      "episode": 1204,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1205,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1206,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1207,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1208,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1209,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1210,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1211,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1212,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1213,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1214,
      "steps": 78,
      "reward": -93.0
    },
    {
      "episode": 1215,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1216,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1217,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1218,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1219,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1220,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1221,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1222,
      "steps": 43,
      "reward": -49.0
    },
    {
      "episode": 1223,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1224,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1225,
      "steps": 51,
      "reward": -30.0
    },
    {
      "episode": 1226,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1227,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1228,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1229,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1230,
      "steps": 102,
      "reward": -126.0
    },
    {
      "episode": 1231,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1232,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1233,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1234,
      "steps": 151,
      "reward": -184.0
    },
    {
      "episode": 1235,
      "steps": 104,
      "reward": -146.0
    },
    {
      "episode": 1236,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1237,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 1238,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1239,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1240,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1241,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1242,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1243,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1244,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1245,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1246,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1247,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1248,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 1249,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1250,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1251,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1252,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1253,
      "steps": 153,
      "reward": -231.0
    },
    {
      "episode": 1254,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1255,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1256,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1257,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 1258,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1259,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1260,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1261,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1262,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1263,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1264,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1265,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1266,
      "steps": 104,
      "reward": -182.0
    },
    {
      "episode": 1267,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1268,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1269,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1270,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1271,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1272,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1273,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1274,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1275,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1276,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1277,
      "steps": 171,
      "reward": -186.0
    },
    {
      "episode": 1278,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1279,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1280,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1281,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1282,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1283,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1284,
      "steps": 42,
      "reward": -21.0
    },
    {
      "episode": 1285,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1286,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1287,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1288,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1289,
      "steps": 196,
      "reward": -238.0
    },
    {
      "episode": 1290,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1291,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1292,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1293,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1294,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1295,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1296,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1297,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1298,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1299,
      "steps": 185,
      "reward": -254.0
    },
    {
      "episode": 1300,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1301,
      "steps": 150,
      "reward": -147.0
    },
    {
      "episode": 1302,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1303,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1304,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1305,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 1306,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1307,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1308,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1309,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1310,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1311,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1312,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1313,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1314,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1315,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1316,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1317,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1318,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1319,
      "steps": 149,
      "reward": -173.0
    },
    {
      "episode": 1320,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1321,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1322,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1323,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1324,
      "steps": 178,
      "reward": -265.0
    },
    {
      "episode": 1325,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1326,
      "steps": 122,
      "reward": -137.0
    },
    {
      "episode": 1327,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1328,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1329,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1330,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1331,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1332,
      "steps": 101,
      "reward": -80.0
    },
    {
      "episode": 1333,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1334,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1335,
      "steps": 142,
      "reward": -166.0
    },
    {
      "episode": 1336,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1337,
      "steps": 169,
      "reward": -220.0
    },
    {
      "episode": 1338,
      "steps": 190,
      "reward": -241.0
    },
    {
      "episode": 1339,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1340,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1341,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1342,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1343,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 1344,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1345,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1346,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1347,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1348,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1349,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1350,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1351,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1352,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1353,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1354,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 1355,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1356,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1357,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1358,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1359,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1360,
      "steps": 23,
      "reward": -29.0
    },
    {
      "episode": 1361,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1362,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1363,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1364,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1365,
      "steps": 150,
      "reward": -183.0
    },
    {
      "episode": 1366,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1367,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1368,
      "steps": 81,
      "reward": -87.0
    },
    {
      "episode": 1369,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1370,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1371,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1372,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1373,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1374,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1375,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1376,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1377,
      "steps": 30,
      "reward": -18.0
    },
    {
      "episode": 1378,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1379,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1380,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1381,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1382,
      "steps": 127,
      "reward": -178.0
    },
    {
      "episode": 1383,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1384,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1385,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1386,
      "steps": 164,
      "reward": -215.0
    },
    {
      "episode": 1387,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1388,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1389,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1390,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1391,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1392,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1393,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1394,
      "steps": 89,
      "reward": -122.0
    },
    {
      "episode": 1395,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1396,
      "steps": 57,
      "reward": -81.0
    },
    {
      "episode": 1397,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1398,
      "steps": 62,
      "reward": -50.0
    },
    {
      "episode": 1399,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1400,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1401,
      "steps": 70,
      "reward": -67.0
    },
    {
      "episode": 1402,
      "steps": 195,
      "reward": -246.0
    },
    {
      "episode": 1403,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1404,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1405,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1406,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1407,
      "steps": 159,
      "reward": -192.0
    },
    {
      "episode": 1408,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1409,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 1410,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1411,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1412,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1413,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1414,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1415,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1416,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1417,
      "steps": 75,
      "reward": -99.0
    },
    {
      "episode": 1418,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1419,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1420,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1421,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1422,
      "steps": 134,
      "reward": -140.0
    },
    {
      "episode": 1423,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1424,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1425,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1426,
      "steps": 101,
      "reward": -170.0
    },
    {
      "episode": 1427,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1428,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1429,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1430,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1431,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1432,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1433,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1434,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1435,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1436,
      "steps": 146,
      "reward": -161.0
    },
    {
      "episode": 1437,
      "steps": 67,
      "reward": -82.0
    },
    {
      "episode": 1438,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1439,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1440,
      "steps": 72,
      "reward": -69.0
    },
    {
      "episode": 1441,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1442,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1443,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1444,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1445,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1446,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1447,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1448,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1449,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1450,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1451,
      "steps": 165,
      "reward": -216.0
    },
    {
      "episode": 1452,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1453,
      "steps": 130,
      "reward": -109.0
    },
    {
      "episode": 1454,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1455,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1456,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1457,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1458,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1459,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1460,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1461,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1462,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1463,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1464,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1465,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1466,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1467,
      "steps": 28,
      "reward": -7.0
    },
    {
      "episode": 1468,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1469,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1470,
      "steps": 123,
      "reward": -174.0
    },
    {
      "episode": 1471,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1472,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1473,
      "steps": 99,
      "reward": -123.0
    },
    {
      "episode": 1474,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1475,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1476,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1477,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1478,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1479,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1480,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1481,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1482,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1483,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1484,
      "steps": 24,
      "reward": -3.0
    },
    {
      "episode": 1485,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1486,
      "steps": 25,
      "reward": -13.0
    },
    {
      "episode": 1487,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1488,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1489,
      "steps": 198,
      "reward": -222.0
    },
    {
      "episode": 1490,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1491,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 1492,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1493,
      "steps": 196,
      "reward": -238.0
    },
    {
      "episode": 1494,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1495,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1496,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1497,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1498,
      "steps": 69,
      "reward": -93.0
    },
    {
      "episode": 1499,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1500,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1501,
      "steps": 139,
      "reward": -181.0
    },
    {
      "episode": 1502,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1503,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1504,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1505,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1506,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1507,
      "steps": 42,
      "reward": -30.0
    },
    {
      "episode": 1508,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1509,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1510,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1511,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1512,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1513,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1514,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1515,
      "steps": 61,
      "reward": -67.0
    },
    {
      "episode": 1516,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1517,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1518,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1519,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1520,
      "steps": 70,
      "reward": -76.0
    },
    {
      "episode": 1521,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1522,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1523,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1524,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1525,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1526,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1527,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1528,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1529,
      "steps": 100,
      "reward": -142.0
    },
    {
      "episode": 1530,
      "steps": 188,
      "reward": -194.0
    },
    {
      "episode": 1531,
      "steps": 135,
      "reward": -195.0
    },
    {
      "episode": 1532,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1533,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1534,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1535,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1536,
      "steps": 115,
      "reward": -139.0
    },
    {
      "episode": 1537,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1538,
      "steps": 165,
      "reward": -207.0
    },
    {
      "episode": 1539,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1540,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1541,
      "steps": 152,
      "reward": -212.0
    },
    {
      "episode": 1542,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1543,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1544,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1545,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1546,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1547,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1548,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1549,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1550,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1551,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1552,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1553,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1554,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1555,
      "steps": 126,
      "reward": -168.0
    },
    {
      "episode": 1556,
      "steps": 142,
      "reward": -175.0
    },
    {
      "episode": 1557,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1558,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1559,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1560,
      "steps": 69,
      "reward": -84.0
    },
    {
      "episode": 1561,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1562,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 1563,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1564,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1565,
      "steps": 62,
      "reward": -122.0
    },
    {
      "episode": 1566,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1567,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1568,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1569,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1570,
      "steps": 160,
      "reward": -193.0
    },
    {
      "episode": 1571,
      "steps": 181,
      "reward": -205.0
    },
    {
      "episode": 1572,
      "steps": 60,
      "reward": -57.0
    },
    {
      "episode": 1573,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1574,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1575,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1576,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1577,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1578,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1579,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1580,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1581,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1582,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1583,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1584,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1585,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1586,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1587,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1588,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 1589,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1590,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1591,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1592,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1593,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 1594,
      "steps": 189,
      "reward": -231.0
    },
    {
      "episode": 1595,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1596,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1597,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1598,
      "steps": 161,
      "reward": -194.0
    },
    {
      "episode": 1599,
      "steps": 143,
      "reward": -158.0
    },
    {
      "episode": 1600,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1601,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1602,
      "steps": 108,
      "reward": -177.0
    },
    {
      "episode": 1603,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1604,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1605,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1606,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1607,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1608,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1609,
      "steps": 95,
      "reward": -101.0
    },
    {
      "episode": 1610,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 1611,
      "steps": 160,
      "reward": -175.0
    },
    {
      "episode": 1612,
      "steps": 145,
      "reward": -169.0
    },
    {
      "episode": 1613,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1614,
      "steps": 152,
      "reward": -149.0
    },
    {
      "episode": 1615,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 1616,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1617,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1618,
      "steps": 151,
      "reward": -166.0
    },
    {
      "episode": 1619,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1620,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 1621,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1622,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1623,
      "steps": 136,
      "reward": -178.0
    },
    {
      "episode": 1624,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1625,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1626,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1627,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1628,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1629,
      "steps": 150,
      "reward": -228.0
    },
    {
      "episode": 1630,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1631,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1632,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1633,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1634,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1635,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1636,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 1637,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1638,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1639,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1640,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1641,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1642,
      "steps": 127,
      "reward": -124.0
    },
    {
      "episode": 1643,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1644,
      "steps": 158,
      "reward": -245.0
    },
    {
      "episode": 1645,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1646,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1647,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1648,
      "steps": 93,
      "reward": -108.0
    },
    {
      "episode": 1649,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1650,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1651,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1652,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1653,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1654,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1655,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 1656,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1657,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 1658,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1659,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1660,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1661,
      "steps": 78,
      "reward": -66.0
    },
    {
      "episode": 1662,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1663,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1664,
      "steps": 150,
      "reward": -201.0
    },
    {
      "episode": 1665,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1666,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 1667,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1668,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1669,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1670,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1671,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1672,
      "steps": 140,
      "reward": -164.0
    },
    {
      "episode": 1673,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1674,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1675,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1676,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1677,
      "steps": 196,
      "reward": -310.0
    },
    {
      "episode": 1678,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1679,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1680,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1681,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1682,
      "steps": 114,
      "reward": -102.0
    },
    {
      "episode": 1683,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 1684,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1685,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1686,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1687,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1688,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1689,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1690,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1691,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1692,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1693,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1694,
      "steps": 63,
      "reward": -60.0
    },
    {
      "episode": 1695,
      "steps": 65,
      "reward": -62.0
    },
    {
      "episode": 1696,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1697,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1698,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1699,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1700,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1701,
      "steps": 115,
      "reward": -121.0
    },
    {
      "episode": 1702,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1703,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1704,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1705,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1706,
      "steps": 148,
      "reward": -181.0
    },
    {
      "episode": 1707,
      "steps": 125,
      "reward": -149.0
    },
    {
      "episode": 1708,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1709,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1710,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1711,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1712,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1713,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1714,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1715,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1716,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1717,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1718,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1719,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1720,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1721,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1722,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1723,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1724,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 1725,
      "steps": 105,
      "reward": -129.0
    },
    {
      "episode": 1726,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1727,
      "steps": 165,
      "reward": -171.0
    },
    {
      "episode": 1728,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1729,
      "steps": 84,
      "reward": -108.0
    },
    {
      "episode": 1730,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1731,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1732,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1733,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1734,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1735,
      "steps": 78,
      "reward": -93.0
    },
    {
      "episode": 1736,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1737,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 1738,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1739,
      "steps": 195,
      "reward": -336.0
    },
    {
      "episode": 1740,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 1741,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1742,
      "steps": 72,
      "reward": -69.0
    },
    {
      "episode": 1743,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1744,
      "steps": 10,
      "reward": 11.0
    },
    {
      "episode": 1745,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1746,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1747,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1748,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1749,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1750,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1751,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 1752,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1753,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1754,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1755,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1756,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1757,
      "steps": 108,
      "reward": -141.0
    },
    {
      "episode": 1758,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1759,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1760,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1761,
      "steps": 74,
      "reward": -80.0
    },
    {
      "episode": 1762,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1763,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1764,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1765,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1766,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1767,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1768,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1769,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1770,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1771,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1772,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1773,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1774,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1775,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1776,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1777,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1778,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1779,
      "steps": 200,
      "reward": -380.0
    },
    {
      "episode": 1780,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1781,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1782,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1783,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1784,
      "steps": 132,
      "reward": -174.0
    },
    {
      "episode": 1785,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1786,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1787,
      "steps": 199,
      "reward": -241.0
    },
    {
      "episode": 1788,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1789,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1790,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1791,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1792,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1793,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1794,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1795,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1796,
      "steps": 152,
      "reward": -194.0
    },
    {
      "episode": 1797,
      "steps": 118,
      "reward": -169.0
    },
    {
      "episode": 1798,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1799,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1800,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1801,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1802,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1803,
      "steps": 23,
      "reward": -20.0
    },
    {
      "episode": 1804,
      "steps": 174,
      "reward": -225.0
    },
    {
      "episode": 1805,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1806,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1807,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1808,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1809,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 1810,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1811,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1812,
      "steps": 100,
      "reward": -88.0
    },
    {
      "episode": 1813,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1814,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1815,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1816,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1817,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1818,
      "steps": 133,
      "reward": -148.0
    },
    {
      "episode": 1819,
      "steps": 129,
      "reward": -180.0
    },
    {
      "episode": 1820,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1821,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1822,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1823,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1824,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1825,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1826,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1827,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1828,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1829,
      "steps": 191,
      "reward": -251.0
    },
    {
      "episode": 1830,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1831,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1832,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1833,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1834,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1835,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1836,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1837,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1838,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1839,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1840,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1841,
      "steps": 62,
      "reward": -68.0
    },
    {
      "episode": 1842,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1843,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1844,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1845,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1846,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1847,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1848,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1849,
      "steps": 199,
      "reward": -259.0
    },
    {
      "episode": 1850,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1851,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1852,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1853,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1854,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1855,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1856,
      "steps": 72,
      "reward": -78.0
    },
    {
      "episode": 1857,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1858,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1859,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1860,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1861,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1862,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1863,
      "steps": 162,
      "reward": -204.0
    },
    {
      "episode": 1864,
      "steps": 68,
      "reward": -92.0
    },
    {
      "episode": 1865,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1866,
      "steps": 199,
      "reward": -250.0
    },
    {
      "episode": 1867,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1868,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1869,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1870,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1871,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1872,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1873,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1874,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1875,
      "steps": 170,
      "reward": -185.0
    },
    {
      "episode": 1876,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1877,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1878,
      "steps": 191,
      "reward": -251.0
    },
    {
      "episode": 1879,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1880,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1881,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1882,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1883,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1884,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1885,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1886,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1887,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1888,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1889,
      "steps": 163,
      "reward": -196.0
    },
    {
      "episode": 1890,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1891,
      "steps": 149,
      "reward": -200.0
    },
    {
      "episode": 1892,
      "steps": 196,
      "reward": -265.0
    },
    {
      "episode": 1893,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1894,
      "steps": 168,
      "reward": -192.0
    },
    {
      "episode": 1895,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1896,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1897,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1898,
      "steps": 162,
      "reward": -186.0
    },
    {
      "episode": 1899,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1900,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1901,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1902,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 1903,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1904,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1905,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1906,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1907,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1908,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1909,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1910,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1911,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1912,
      "steps": 131,
      "reward": -155.0
    },
    {
      "episode": 1913,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 1914,
      "steps": 51,
      "reward": -39.0
    },
    {
      "episode": 1915,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1916,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1917,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1918,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1919,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1920,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1921,
      "steps": 109,
      "reward": -115.0
    },
    {
      "episode": 1922,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 1923,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1924,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1925,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1926,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1927,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1928,
      "steps": 47,
      "reward": -62.0
    },
    {
      "episode": 1929,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1930,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 1931,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1932,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1933,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1934,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1935,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1936,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1937,
      "steps": 133,
      "reward": -175.0
    },
    {
      "episode": 1938,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1939,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1940,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1941,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1942,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1943,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 1944,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1945,
      "steps": 176,
      "reward": -200.0
    },
    {
      "episode": 1946,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1947,
      "steps": 41,
      "reward": -29.0
    },
    {
      "episode": 1948,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1949,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1950,
      "steps": 32,
      "reward": -11.0
    },
    {
      "episode": 1951,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1952,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1953,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1954,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1955,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1956,
      "steps": 90,
      "reward": -87.0
    },
    {
      "episode": 1957,
      "steps": 158,
      "reward": -173.0
    },
    {
      "episode": 1958,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1959,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1960,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1961,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1962,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1963,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1964,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1965,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1966,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1967,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1968,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1969,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1970,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1971,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 1972,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1973,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1974,
      "steps": 97,
      "reward": -94.0
    },
    {
      "episode": 1975,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1976,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1977,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 1978,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1979,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 1980,
      "steps": 181,
      "reward": -187.0
    },
    {
      "episode": 1981,
      "steps": 118,
      "reward": -142.0
    },
    {
      "episode": 1982,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1983,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 1984,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 1985,
      "steps": 122,
      "reward": -128.0
    },
    {
      "episode": 1986,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1987,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 1988,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1989,
      "steps": 46,
      "reward": -25.0
    },
    {
      "episode": 1990,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 1991,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1992,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 1993,
      "steps": 186,
      "reward": -246.0
    },
    {
      "episode": 1994,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1995,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 1996,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 1997,
      "steps": 91,
      "reward": -70.0
    },
    {
      "episode": 1998,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 1999,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2000,
      "steps": 185,
      "reward": -245.0
    },
    {
      "episode": 2001,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2002,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 2003,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2004,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2005,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2006,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2007,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2008,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2009,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2010,
      "steps": 120,
      "reward": -126.0
    },
    {
      "episode": 2011,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2012,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2013,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2014,
      "steps": 118,
      "reward": -133.0
    },
    {
      "episode": 2015,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2016,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2017,
      "steps": 193,
      "reward": -199.0
    },
    {
      "episode": 2018,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2019,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2020,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2021,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2022,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2023,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2024,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2025,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2026,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2027,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2028,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2029,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2030,
      "steps": 126,
      "reward": -213.0
    },
    {
      "episode": 2031,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2032,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2033,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2034,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2035,
      "steps": 113,
      "reward": -137.0
    },
    {
      "episode": 2036,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2037,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2038,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 2039,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2040,
      "steps": 157,
      "reward": -208.0
    },
    {
      "episode": 2041,
      "steps": 139,
      "reward": -217.0
    },
    {
      "episode": 2042,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2043,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2044,
      "steps": 179,
      "reward": -239.0
    },
    {
      "episode": 2045,
      "steps": 123,
      "reward": -147.0
    },
    {
      "episode": 2046,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2047,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2048,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2049,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2050,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2051,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2052,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2053,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2054,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2055,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2056,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2057,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2058,
      "steps": 96,
      "reward": -111.0
    },
    {
      "episode": 2059,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2060,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2061,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2062,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2063,
      "steps": 138,
      "reward": -135.0
    },
    {
      "episode": 2064,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2065,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2066,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2067,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2068,
      "steps": 135,
      "reward": -150.0
    },
    {
      "episode": 2069,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2070,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2071,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2072,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2073,
      "steps": 16,
      "reward": -4.0
    },
    {
      "episode": 2074,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2075,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2076,
      "steps": 171,
      "reward": -258.0
    },
    {
      "episode": 2077,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2078,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2079,
      "steps": 184,
      "reward": -271.0
    },
    {
      "episode": 2080,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2081,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2082,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2083,
      "steps": 106,
      "reward": -112.0
    },
    {
      "episode": 2084,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2085,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2086,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2087,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2088,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2089,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2090,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2091,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2092,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2093,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2094,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2095,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2096,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2097,
      "steps": 195,
      "reward": -210.0
    },
    {
      "episode": 2098,
      "steps": 162,
      "reward": -213.0
    },
    {
      "episode": 2099,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2100,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2101,
      "steps": 72,
      "reward": -69.0
    },
    {
      "episode": 2102,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2103,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2104,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2105,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2106,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2107,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2108,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2109,
      "steps": 149,
      "reward": -200.0
    },
    {
      "episode": 2110,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2111,
      "steps": 92,
      "reward": -98.0
    },
    {
      "episode": 2112,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2113,
      "steps": 88,
      "reward": -103.0
    },
    {
      "episode": 2114,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2115,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2116,
      "steps": 122,
      "reward": -164.0
    },
    {
      "episode": 2117,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2118,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2119,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2120,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2121,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2122,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2123,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2124,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2125,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2126,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2127,
      "steps": 107,
      "reward": -140.0
    },
    {
      "episode": 2128,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2129,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2130,
      "steps": 132,
      "reward": -165.0
    },
    {
      "episode": 2131,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2132,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2133,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2134,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2135,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2136,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2137,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2138,
      "steps": 130,
      "reward": -127.0
    },
    {
      "episode": 2139,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2140,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2141,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2142,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2143,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2144,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2145,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2146,
      "steps": 56,
      "reward": -71.0
    },
    {
      "episode": 2147,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2148,
      "steps": 71,
      "reward": -122.0
    },
    {
      "episode": 2149,
      "steps": 66,
      "reward": -63.0
    },
    {
      "episode": 2150,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2151,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2152,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2153,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2154,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2155,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2156,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2157,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2158,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2159,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2160,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2161,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2162,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 2163,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2164,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2165,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2166,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2167,
      "steps": 15,
      "reward": -3.0
    },
    {
      "episode": 2168,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2169,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2170,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2171,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2172,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2173,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2174,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2175,
      "steps": 135,
      "reward": -150.0
    },
    {
      "episode": 2176,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2177,
      "steps": 200,
      "reward": -296.0
    },
    {
      "episode": 2178,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2179,
      "steps": 161,
      "reward": -194.0
    },
    {
      "episode": 2180,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2181,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2182,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2183,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2184,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2185,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2186,
      "steps": 148,
      "reward": -172.0
    },
    {
      "episode": 2187,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2188,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2189,
      "steps": 192,
      "reward": -243.0
    },
    {
      "episode": 2190,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2191,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2192,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2193,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2194,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2195,
      "steps": 156,
      "reward": -198.0
    },
    {
      "episode": 2196,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2197,
      "steps": 73,
      "reward": -97.0
    },
    {
      "episode": 2198,
      "steps": 27,
      "reward": -15.0
    },
    {
      "episode": 2199,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2200,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2201,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2202,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 2203,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2204,
      "steps": 143,
      "reward": -185.0
    },
    {
      "episode": 2205,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2206,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2207,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2208,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2209,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2210,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2211,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2212,
      "steps": 171,
      "reward": -240.0
    },
    {
      "episode": 2213,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2214,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2215,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2216,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2217,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2218,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2219,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2220,
      "steps": 146,
      "reward": -215.0
    },
    {
      "episode": 2221,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2222,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2223,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2224,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2225,
      "steps": 31,
      "reward": -19.0
    },
    {
      "episode": 2226,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2227,
      "steps": 144,
      "reward": -150.0
    },
    {
      "episode": 2228,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2229,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2230,
      "steps": 162,
      "reward": -231.0
    },
    {
      "episode": 2231,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2232,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2233,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2234,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2235,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2236,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2237,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2238,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2239,
      "steps": 34,
      "reward": -22.0
    },
    {
      "episode": 2240,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2241,
      "steps": 138,
      "reward": -153.0
    },
    {
      "episode": 2242,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2243,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2244,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2245,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2246,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2247,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2248,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2249,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2250,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2251,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2252,
      "steps": 141,
      "reward": -183.0
    },
    {
      "episode": 2253,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2254,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2255,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2256,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2257,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2258,
      "steps": 126,
      "reward": -159.0
    },
    {
      "episode": 2259,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2260,
      "steps": 110,
      "reward": -143.0
    },
    {
      "episode": 2261,
      "steps": 139,
      "reward": -172.0
    },
    {
      "episode": 2262,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2263,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2264,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2265,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2266,
      "steps": 125,
      "reward": -149.0
    },
    {
      "episode": 2267,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2268,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2269,
      "steps": 183,
      "reward": -261.0
    },
    {
      "episode": 2270,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2271,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2272,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2273,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2274,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2275,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2276,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2277,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2278,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2279,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2280,
      "steps": 74,
      "reward": -62.0
    },
    {
      "episode": 2281,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2282,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2283,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2284,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2285,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2286,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2287,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 2288,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2289,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2290,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2291,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2292,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2293,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2294,
      "steps": 86,
      "reward": -92.0
    },
    {
      "episode": 2295,
      "steps": 100,
      "reward": -133.0
    },
    {
      "episode": 2296,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2297,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2298,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2299,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2300,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2301,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2302,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2303,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2304,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2305,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2306,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2307,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2308,
      "steps": 114,
      "reward": -147.0
    },
    {
      "episode": 2309,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2310,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2311,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2312,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2313,
      "steps": 60,
      "reward": -48.0
    },
    {
      "episode": 2314,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2315,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2316,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2317,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2318,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2319,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2320,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2321,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2322,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2323,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2324,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2325,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2326,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2327,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2328,
      "steps": 194,
      "reward": -263.0
    },
    {
      "episode": 2329,
      "steps": 90,
      "reward": -87.0
    },
    {
      "episode": 2330,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2331,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2332,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2333,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2334,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2335,
      "steps": 85,
      "reward": -118.0
    },
    {
      "episode": 2336,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2337,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2338,
      "steps": 107,
      "reward": -122.0
    },
    {
      "episode": 2339,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2340,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2341,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2342,
      "steps": 46,
      "reward": -34.0
    },
    {
      "episode": 2343,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2344,
      "steps": 154,
      "reward": -223.0
    },
    {
      "episode": 2345,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2346,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2347,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2348,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2349,
      "steps": 132,
      "reward": -129.0
    },
    {
      "episode": 2350,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2351,
      "steps": 196,
      "reward": -238.0
    },
    {
      "episode": 2352,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2353,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2354,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2355,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2356,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2357,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 2358,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2359,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2360,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2361,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2362,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2363,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2364,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2365,
      "steps": 43,
      "reward": -22.0
    },
    {
      "episode": 2366,
      "steps": 184,
      "reward": -217.0
    },
    {
      "episode": 2367,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2368,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2369,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2370,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2371,
      "steps": 132,
      "reward": -165.0
    },
    {
      "episode": 2372,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2373,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2374,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2375,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 2376,
      "steps": 187,
      "reward": -238.0
    },
    {
      "episode": 2377,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2378,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2379,
      "steps": 140,
      "reward": -200.0
    },
    {
      "episode": 2380,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2381,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2382,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2383,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2384,
      "steps": 184,
      "reward": -208.0
    },
    {
      "episode": 2385,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2386,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2387,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2388,
      "steps": 78,
      "reward": -84.0
    },
    {
      "episode": 2389,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2390,
      "steps": 123,
      "reward": -147.0
    },
    {
      "episode": 2391,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2392,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2393,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2394,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2395,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2396,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2397,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 2398,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2399,
      "steps": 66,
      "reward": -72.0
    },
    {
      "episode": 2400,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2401,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2402,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2403,
      "steps": 24,
      "reward": -12.0
    },
    {
      "episode": 2404,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 2405,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2406,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2407,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2408,
      "steps": 82,
      "reward": -88.0
    },
    {
      "episode": 2409,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2410,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2411,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2412,
      "steps": 171,
      "reward": -213.0
    },
    {
      "episode": 2413,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2414,
      "steps": 172,
      "reward": -223.0
    },
    {
      "episode": 2415,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2416,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2417,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2418,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2419,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2420,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2421,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2422,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2423,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2424,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2425,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2426,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2427,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2428,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2429,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2430,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2431,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2432,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2433,
      "steps": 166,
      "reward": -181.0
    },
    {
      "episode": 2434,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2435,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2436,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2437,
      "steps": 38,
      "reward": -53.0
    },
    {
      "episode": 2438,
      "steps": 120,
      "reward": -162.0
    },
    {
      "episode": 2439,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2440,
      "steps": 120,
      "reward": -135.0
    },
    {
      "episode": 2441,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2442,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2443,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2444,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2445,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2446,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2447,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2448,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2449,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2450,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2451,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2452,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2453,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2454,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2455,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2456,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2457,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2458,
      "steps": 159,
      "reward": -228.0
    },
    {
      "episode": 2459,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2460,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2461,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2462,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2463,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2464,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2465,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2466,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2467,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2468,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2469,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2470,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2471,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2472,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2473,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2474,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2475,
      "steps": 106,
      "reward": -94.0
    },
    {
      "episode": 2476,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2477,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2478,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2479,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2480,
      "steps": 28,
      "reward": -25.0
    },
    {
      "episode": 2481,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2482,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2483,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2484,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2485,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2486,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2487,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2488,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2489,
      "steps": 102,
      "reward": -153.0
    },
    {
      "episode": 2490,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2491,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2492,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 2493,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2494,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2495,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2496,
      "steps": 61,
      "reward": -67.0
    },
    {
      "episode": 2497,
      "steps": 189,
      "reward": -240.0
    },
    {
      "episode": 2498,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2499,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2500,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2501,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2502,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2503,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2504,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2505,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2506,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2507,
      "steps": 50,
      "reward": -47.0
    },
    {
      "episode": 2508,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2509,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2510,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2511,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2512,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2513,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2514,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2515,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2516,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2517,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2518,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2519,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 2520,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2521,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2522,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2523,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2524,
      "steps": 58,
      "reward": -37.0
    },
    {
      "episode": 2525,
      "steps": 194,
      "reward": -200.0
    },
    {
      "episode": 2526,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 2527,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2528,
      "steps": 153,
      "reward": -177.0
    },
    {
      "episode": 2529,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2530,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2531,
      "steps": 40,
      "reward": -55.0
    },
    {
      "episode": 2532,
      "steps": 55,
      "reward": -70.0
    },
    {
      "episode": 2533,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2534,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2535,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2536,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2537,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2538,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2539,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2540,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2541,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2542,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2543,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2544,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2545,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2546,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2547,
      "steps": 146,
      "reward": -179.0
    },
    {
      "episode": 2548,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2549,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2550,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2551,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2552,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2553,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2554,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2555,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2556,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2557,
      "steps": 105,
      "reward": -138.0
    },
    {
      "episode": 2558,
      "steps": 64,
      "reward": -52.0
    },
    {
      "episode": 2559,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2560,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2561,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2562,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2563,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2564,
      "steps": 164,
      "reward": -197.0
    },
    {
      "episode": 2565,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2566,
      "steps": 99,
      "reward": -87.0
    },
    {
      "episode": 2567,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2568,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2569,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2570,
      "steps": 101,
      "reward": -98.0
    },
    {
      "episode": 2571,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2572,
      "steps": 83,
      "reward": -89.0
    },
    {
      "episode": 2573,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2574,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2575,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2576,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2577,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2578,
      "steps": 151,
      "reward": -211.0
    },
    {
      "episode": 2579,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2580,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2581,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2582,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2583,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 2584,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2585,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2586,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2587,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2588,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2589,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2590,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2591,
      "steps": 183,
      "reward": -189.0
    },
    {
      "episode": 2592,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2593,
      "steps": 191,
      "reward": -224.0
    },
    {
      "episode": 2594,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2595,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2596,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2597,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2598,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2599,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2600,
      "steps": 152,
      "reward": -212.0
    },
    {
      "episode": 2601,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2602,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2603,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2604,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2605,
      "steps": 158,
      "reward": -182.0
    },
    {
      "episode": 2606,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2607,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 2608,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2609,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2610,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2611,
      "steps": 115,
      "reward": -130.0
    },
    {
      "episode": 2612,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2613,
      "steps": 198,
      "reward": -258.0
    },
    {
      "episode": 2614,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2615,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2616,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2617,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2618,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2619,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2620,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2621,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2622,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2623,
      "steps": 200,
      "reward": -371.0
    },
    {
      "episode": 2624,
      "steps": 179,
      "reward": -248.0
    },
    {
      "episode": 2625,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2626,
      "steps": 148,
      "reward": -172.0
    },
    {
      "episode": 2627,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2628,
      "steps": 123,
      "reward": -120.0
    },
    {
      "episode": 2629,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2630,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2631,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2632,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2633,
      "steps": 116,
      "reward": -113.0
    },
    {
      "episode": 2634,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2635,
      "steps": 38,
      "reward": -17.0
    },
    {
      "episode": 2636,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2637,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2638,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2639,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2640,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2641,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2642,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2643,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2644,
      "steps": 150,
      "reward": -201.0
    },
    {
      "episode": 2645,
      "steps": 110,
      "reward": -116.0
    },
    {
      "episode": 2646,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2647,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2648,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2649,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2650,
      "steps": 76,
      "reward": -100.0
    },
    {
      "episode": 2651,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2652,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2653,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2654,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2655,
      "steps": 171,
      "reward": -195.0
    },
    {
      "episode": 2656,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2657,
      "steps": 111,
      "reward": -108.0
    },
    {
      "episode": 2658,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2659,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2660,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2661,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2662,
      "steps": 195,
      "reward": -264.0
    },
    {
      "episode": 2663,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2664,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2665,
      "steps": 198,
      "reward": -258.0
    },
    {
      "episode": 2666,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2667,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2668,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2669,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2670,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2671,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2672,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2673,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2674,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2675,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2676,
      "steps": 22,
      "reward": -19.0
    },
    {
      "episode": 2677,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2678,
      "steps": 146,
      "reward": -143.0
    },
    {
      "episode": 2679,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2680,
      "steps": 57,
      "reward": -54.0
    },
    {
      "episode": 2681,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2682,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2683,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2684,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2685,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2686,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2687,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 2688,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2689,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2690,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2691,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2692,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2693,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2694,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2695,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2696,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2697,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2698,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2699,
      "steps": 100,
      "reward": -115.0
    },
    {
      "episode": 2700,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2701,
      "steps": 134,
      "reward": -194.0
    },
    {
      "episode": 2702,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2703,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2704,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2705,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2706,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2707,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 2708,
      "steps": 53,
      "reward": -68.0
    },
    {
      "episode": 2709,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2710,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2711,
      "steps": 189,
      "reward": -204.0
    },
    {
      "episode": 2712,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2713,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2714,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2715,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2716,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2717,
      "steps": 56,
      "reward": -62.0
    },
    {
      "episode": 2718,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2719,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2720,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2721,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2722,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2723,
      "steps": 140,
      "reward": -155.0
    },
    {
      "episode": 2724,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2725,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2726,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2727,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2728,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2729,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2730,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2731,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2732,
      "steps": 166,
      "reward": -190.0
    },
    {
      "episode": 2733,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2734,
      "steps": 115,
      "reward": -130.0
    },
    {
      "episode": 2735,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2736,
      "steps": 115,
      "reward": -130.0
    },
    {
      "episode": 2737,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2738,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2739,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2740,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2741,
      "steps": 43,
      "reward": -58.0
    },
    {
      "episode": 2742,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2743,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2744,
      "steps": 132,
      "reward": -156.0
    },
    {
      "episode": 2745,
      "steps": 200,
      "reward": -371.0
    },
    {
      "episode": 2746,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2747,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2748,
      "steps": 146,
      "reward": -197.0
    },
    {
      "episode": 2749,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2750,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2751,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2752,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2753,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2754,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2755,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2756,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2757,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2758,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2759,
      "steps": 33,
      "reward": -21.0
    },
    {
      "episode": 2760,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2761,
      "steps": 131,
      "reward": -119.0
    },
    {
      "episode": 2762,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2763,
      "steps": 93,
      "reward": -108.0
    },
    {
      "episode": 2764,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2765,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2766,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2767,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2768,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2769,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2770,
      "steps": 46,
      "reward": -43.0
    },
    {
      "episode": 2771,
      "steps": 14,
      "reward": 7.0
    },
    {
      "episode": 2772,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2773,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2774,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2775,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2776,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2777,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2778,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2779,
      "steps": 134,
      "reward": -140.0
    },
    {
      "episode": 2780,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2781,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2782,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2783,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2784,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2785,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2786,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2787,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2788,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2789,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2790,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2791,
      "steps": 154,
      "reward": -205.0
    },
    {
      "episode": 2792,
      "steps": 21,
      "reward": -9.0
    },
    {
      "episode": 2793,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2794,
      "steps": 111,
      "reward": -117.0
    },
    {
      "episode": 2795,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 2796,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2797,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2798,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2799,
      "steps": 104,
      "reward": -110.0
    },
    {
      "episode": 2800,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2801,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2802,
      "steps": 161,
      "reward": -257.0
    },
    {
      "episode": 2803,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2804,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2805,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2806,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2807,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2808,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2809,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2810,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2811,
      "steps": 56,
      "reward": -53.0
    },
    {
      "episode": 2812,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 2813,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2814,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2815,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2816,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2817,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2818,
      "steps": 174,
      "reward": -216.0
    },
    {
      "episode": 2819,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2820,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2821,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2822,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2823,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2824,
      "steps": 66,
      "reward": -45.0
    },
    {
      "episode": 2825,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2826,
      "steps": 40,
      "reward": -28.0
    },
    {
      "episode": 2827,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2828,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2829,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2830,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2831,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2832,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 2833,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2834,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2835,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2836,
      "steps": 54,
      "reward": -42.0
    },
    {
      "episode": 2837,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2838,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2839,
      "steps": 141,
      "reward": -165.0
    },
    {
      "episode": 2840,
      "steps": 174,
      "reward": -198.0
    },
    {
      "episode": 2841,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2842,
      "steps": 139,
      "reward": -154.0
    },
    {
      "episode": 2843,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2844,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2845,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2846,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2847,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2848,
      "steps": 159,
      "reward": -219.0
    },
    {
      "episode": 2849,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2850,
      "steps": 154,
      "reward": -214.0
    },
    {
      "episode": 2851,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2852,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2853,
      "steps": 172,
      "reward": -223.0
    },
    {
      "episode": 2854,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2855,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2856,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2857,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2858,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2859,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2860,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2861,
      "steps": 185,
      "reward": -272.0
    },
    {
      "episode": 2862,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2863,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2864,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2865,
      "steps": 43,
      "reward": -22.0
    },
    {
      "episode": 2866,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2867,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2868,
      "steps": 103,
      "reward": -127.0
    },
    {
      "episode": 2869,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2870,
      "steps": 81,
      "reward": -87.0
    },
    {
      "episode": 2871,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 2872,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 2873,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2874,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2875,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2876,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2877,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2878,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2879,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2880,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2881,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2882,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2883,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2884,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2885,
      "steps": 170,
      "reward": -212.0
    },
    {
      "episode": 2886,
      "steps": 147,
      "reward": -153.0
    },
    {
      "episode": 2887,
      "steps": 68,
      "reward": -56.0
    },
    {
      "episode": 2888,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2889,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2890,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2891,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2892,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 2893,
      "steps": 182,
      "reward": -206.0
    },
    {
      "episode": 2894,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2895,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2896,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2897,
      "steps": 173,
      "reward": -233.0
    },
    {
      "episode": 2898,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2899,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2900,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2901,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2902,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2903,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2904,
      "steps": 181,
      "reward": -214.0
    },
    {
      "episode": 2905,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2906,
      "steps": 34,
      "reward": -40.0
    },
    {
      "episode": 2907,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2908,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2909,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2910,
      "steps": 168,
      "reward": -174.0
    },
    {
      "episode": 2911,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2912,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2913,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2914,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2915,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2916,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2917,
      "steps": 34,
      "reward": -22.0
    },
    {
      "episode": 2918,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2919,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2920,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 2921,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2922,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2923,
      "steps": 38,
      "reward": -17.0
    },
    {
      "episode": 2924,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2925,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2926,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2927,
      "steps": 9,
      "reward": 3.0
    },
    {
      "episode": 2928,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2929,
      "steps": 120,
      "reward": -135.0
    },
    {
      "episode": 2930,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2931,
      "steps": 200,
      "reward": -209.0
    },
    {
      "episode": 2932,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2933,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2934,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2935,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2936,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2937,
      "steps": 66,
      "reward": -72.0
    },
    {
      "episode": 2938,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2939,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2940,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2941,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2942,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2943,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2944,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2945,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2946,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2947,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2948,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 2949,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2950,
      "steps": 113,
      "reward": -155.0
    },
    {
      "episode": 2951,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2952,
      "steps": 163,
      "reward": -205.0
    },
    {
      "episode": 2953,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2954,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2955,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2956,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2957,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2958,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2959,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2960,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2961,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 2962,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2963,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2964,
      "steps": 146,
      "reward": -170.0
    },
    {
      "episode": 2965,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2966,
      "steps": 197,
      "reward": -257.0
    },
    {
      "episode": 2967,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2968,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2969,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2970,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2971,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2972,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2973,
      "steps": 102,
      "reward": -126.0
    },
    {
      "episode": 2974,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2975,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2976,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2977,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2978,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2979,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 2980,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 2981,
      "steps": 44,
      "reward": -41.0
    },
    {
      "episode": 2982,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 2983,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 2984,
      "steps": 199,
      "reward": -277.0
    },
    {
      "episode": 2985,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2986,
      "steps": 64,
      "reward": -61.0
    },
    {
      "episode": 2987,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 2988,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 2989,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2990,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2991,
      "steps": 24,
      "reward": -12.0
    },
    {
      "episode": 2992,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 2993,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2994,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 2995,
      "steps": 179,
      "reward": -266.0
    },
    {
      "episode": 2996,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 2997,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 2998,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 2999,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3000,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3001,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3002,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3003,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3004,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3005,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3006,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3007,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3008,
      "steps": 173,
      "reward": -197.0
    },
    {
      "episode": 3009,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3010,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3011,
      "steps": 161,
      "reward": -221.0
    },
    {
      "episode": 3012,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 3013,
      "steps": 133,
      "reward": -148.0
    },
    {
      "episode": 3014,
      "steps": 187,
      "reward": -220.0
    },
    {
      "episode": 3015,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3016,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3017,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3018,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3019,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3020,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3021,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3022,
      "steps": 174,
      "reward": -216.0
    },
    {
      "episode": 3023,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3024,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3025,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3026,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3027,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3028,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3029,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3030,
      "steps": 124,
      "reward": -193.0
    },
    {
      "episode": 3031,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3032,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3033,
      "steps": 151,
      "reward": -148.0
    },
    {
      "episode": 3034,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3035,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3036,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3037,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3038,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3039,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3040,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 3041,
      "steps": 45,
      "reward": -42.0
    },
    {
      "episode": 3042,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3043,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3044,
      "steps": 77,
      "reward": -119.0
    },
    {
      "episode": 3045,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3046,
      "steps": 120,
      "reward": -153.0
    },
    {
      "episode": 3047,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3048,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3049,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3050,
      "steps": 116,
      "reward": -149.0
    },
    {
      "episode": 3051,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3052,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3053,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3054,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3055,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3056,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3057,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3058,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3059,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3060,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3061,
      "steps": 17,
      "reward": -5.0
    },
    {
      "episode": 3062,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3063,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3064,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3065,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3066,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3067,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3068,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3069,
      "steps": 112,
      "reward": -100.0
    },
    {
      "episode": 3070,
      "steps": 154,
      "reward": -214.0
    },
    {
      "episode": 3071,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3072,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3073,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3074,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3075,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3076,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3077,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3078,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3079,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3080,
      "steps": 153,
      "reward": -159.0
    },
    {
      "episode": 3081,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3082,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3083,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3084,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3085,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3086,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3087,
      "steps": 119,
      "reward": -143.0
    },
    {
      "episode": 3088,
      "steps": 108,
      "reward": -132.0
    },
    {
      "episode": 3089,
      "steps": 117,
      "reward": -114.0
    },
    {
      "episode": 3090,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3091,
      "steps": 131,
      "reward": -182.0
    },
    {
      "episode": 3092,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3093,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3094,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3095,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3096,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3097,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3098,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3099,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3100,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3101,
      "steps": 22,
      "reward": -1.0
    },
    {
      "episode": 3102,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3103,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3104,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3105,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3106,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3107,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3108,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3109,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3110,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3111,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3112,
      "steps": 79,
      "reward": -67.0
    },
    {
      "episode": 3113,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3114,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3115,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3116,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3117,
      "steps": 60,
      "reward": -39.0
    },
    {
      "episode": 3118,
      "steps": 176,
      "reward": -236.0
    },
    {
      "episode": 3119,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3120,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3121,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3122,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3123,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3124,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3125,
      "steps": 133,
      "reward": -175.0
    },
    {
      "episode": 3126,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3127,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3128,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 3129,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3130,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3131,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3132,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3133,
      "steps": 152,
      "reward": -194.0
    },
    {
      "episode": 3134,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3135,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3136,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3137,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3138,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3139,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3140,
      "steps": 165,
      "reward": -252.0
    },
    {
      "episode": 3141,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3142,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3143,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3144,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3145,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3146,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3147,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3148,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3149,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3150,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3151,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3152,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3153,
      "steps": 51,
      "reward": -75.0
    },
    {
      "episode": 3154,
      "steps": 85,
      "reward": -136.0
    },
    {
      "episode": 3155,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3156,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3157,
      "steps": 72,
      "reward": -78.0
    },
    {
      "episode": 3158,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3159,
      "steps": 66,
      "reward": -72.0
    },
    {
      "episode": 3160,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3161,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3162,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3163,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3164,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3165,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3166,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3167,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3168,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3169,
      "steps": 140,
      "reward": -155.0
    },
    {
      "episode": 3170,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3171,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3172,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3173,
      "steps": 78,
      "reward": -84.0
    },
    {
      "episode": 3174,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3175,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3176,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3177,
      "steps": 165,
      "reward": -207.0
    },
    {
      "episode": 3178,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3179,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3180,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3181,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3182,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3183,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3184,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3185,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3186,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3187,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3188,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3189,
      "steps": 122,
      "reward": -200.0
    },
    {
      "episode": 3190,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3191,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3192,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3193,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3194,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3195,
      "steps": 18,
      "reward": 3.0
    },
    {
      "episode": 3196,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3197,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3198,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3199,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3200,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3201,
      "steps": 111,
      "reward": -117.0
    },
    {
      "episode": 3202,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3203,
      "steps": 200,
      "reward": -209.0
    },
    {
      "episode": 3204,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3205,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3206,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3207,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3208,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3209,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3210,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3211,
      "steps": 141,
      "reward": -156.0
    },
    {
      "episode": 3212,
      "steps": 176,
      "reward": -236.0
    },
    {
      "episode": 3213,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 3214,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3215,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3216,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3217,
      "steps": 162,
      "reward": -231.0
    },
    {
      "episode": 3218,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3219,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3220,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3221,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3222,
      "steps": 50,
      "reward": -56.0
    },
    {
      "episode": 3223,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3224,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3225,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3226,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3227,
      "steps": 144,
      "reward": -195.0
    },
    {
      "episode": 3228,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3229,
      "steps": 163,
      "reward": -187.0
    },
    {
      "episode": 3230,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3231,
      "steps": 184,
      "reward": -235.0
    },
    {
      "episode": 3232,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3233,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3234,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3235,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3236,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3237,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3238,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3239,
      "steps": 126,
      "reward": -141.0
    },
    {
      "episode": 3240,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3241,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3242,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3243,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3244,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3245,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3246,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3247,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3248,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3249,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3250,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3251,
      "steps": 97,
      "reward": -85.0
    },
    {
      "episode": 3252,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3253,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3254,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3255,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3256,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3257,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3258,
      "steps": 53,
      "reward": -50.0
    },
    {
      "episode": 3259,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3260,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3261,
      "steps": 93,
      "reward": -117.0
    },
    {
      "episode": 3262,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3263,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3264,
      "steps": 103,
      "reward": -154.0
    },
    {
      "episode": 3265,
      "steps": 200,
      "reward": -362.0
    },
    {
      "episode": 3266,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3267,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3268,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3269,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3270,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3271,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3272,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3273,
      "steps": 162,
      "reward": -195.0
    },
    {
      "episode": 3274,
      "steps": 136,
      "reward": -169.0
    },
    {
      "episode": 3275,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3276,
      "steps": 149,
      "reward": -164.0
    },
    {
      "episode": 3277,
      "steps": 125,
      "reward": -113.0
    },
    {
      "episode": 3278,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3279,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3280,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3281,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3282,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3283,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3284,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3285,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3286,
      "steps": 147,
      "reward": -180.0
    },
    {
      "episode": 3287,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3288,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3289,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3290,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3291,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3292,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3293,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3294,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3295,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3296,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3297,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3298,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3299,
      "steps": 90,
      "reward": -87.0
    },
    {
      "episode": 3300,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3301,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3302,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3303,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3304,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3305,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3306,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3307,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3308,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3309,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3310,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3311,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3312,
      "steps": 193,
      "reward": -226.0
    },
    {
      "episode": 3313,
      "steps": 149,
      "reward": -173.0
    },
    {
      "episode": 3314,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 3315,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3316,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3317,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 3318,
      "steps": 149,
      "reward": -182.0
    },
    {
      "episode": 3319,
      "steps": 63,
      "reward": -87.0
    },
    {
      "episode": 3320,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3321,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3322,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3323,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3324,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3325,
      "steps": 47,
      "reward": -53.0
    },
    {
      "episode": 3326,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3327,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3328,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3329,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3330,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3331,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3332,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3333,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3334,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3335,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3336,
      "steps": 41,
      "reward": -38.0
    },
    {
      "episode": 3337,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3338,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3339,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3340,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3341,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3342,
      "steps": 59,
      "reward": -65.0
    },
    {
      "episode": 3343,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3344,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3345,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3346,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3347,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3348,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3349,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3350,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3351,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3352,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3353,
      "steps": 67,
      "reward": -64.0
    },
    {
      "episode": 3354,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3355,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3356,
      "steps": 115,
      "reward": -103.0
    },
    {
      "episode": 3357,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3358,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3359,
      "steps": 158,
      "reward": -182.0
    },
    {
      "episode": 3360,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3361,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3362,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3363,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3364,
      "steps": 63,
      "reward": -60.0
    },
    {
      "episode": 3365,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3366,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3367,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3368,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3369,
      "steps": 159,
      "reward": -192.0
    },
    {
      "episode": 3370,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3371,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3372,
      "steps": 145,
      "reward": -151.0
    },
    {
      "episode": 3373,
      "steps": 152,
      "reward": -221.0
    },
    {
      "episode": 3374,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3375,
      "steps": 157,
      "reward": -190.0
    },
    {
      "episode": 3376,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3377,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3378,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3379,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3380,
      "steps": 191,
      "reward": -260.0
    },
    {
      "episode": 3381,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3382,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3383,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 3384,
      "steps": 106,
      "reward": -103.0
    },
    {
      "episode": 3385,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3386,
      "steps": 177,
      "reward": -264.0
    },
    {
      "episode": 3387,
      "steps": 32,
      "reward": -20.0
    },
    {
      "episode": 3388,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3389,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3390,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3391,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3392,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3393,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3394,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3395,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3396,
      "steps": 130,
      "reward": -181.0
    },
    {
      "episode": 3397,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3398,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3399,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3400,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3401,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3402,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3403,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3404,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3405,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3406,
      "steps": 187,
      "reward": -211.0
    },
    {
      "episode": 3407,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3408,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3409,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3410,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3411,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3412,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3413,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3414,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3415,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 3416,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3417,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3418,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3419,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3420,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3421,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3422,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3423,
      "steps": 117,
      "reward": -168.0
    },
    {
      "episode": 3424,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3425,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3426,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3427,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 3428,
      "steps": 191,
      "reward": -251.0
    },
    {
      "episode": 3429,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3430,
      "steps": 96,
      "reward": -102.0
    },
    {
      "episode": 3431,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3432,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3433,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3434,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3435,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3436,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3437,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3438,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3439,
      "steps": 29,
      "reward": -17.0
    },
    {
      "episode": 3440,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3441,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3442,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3443,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3444,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3445,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3446,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3447,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3448,
      "steps": 172,
      "reward": -223.0
    },
    {
      "episode": 3449,
      "steps": 28,
      "reward": -16.0
    },
    {
      "episode": 3450,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3451,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3452,
      "steps": 71,
      "reward": -86.0
    },
    {
      "episode": 3453,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3454,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3455,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3456,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3457,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3458,
      "steps": 66,
      "reward": -45.0
    },
    {
      "episode": 3459,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3460,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3461,
      "steps": 190,
      "reward": -214.0
    },
    {
      "episode": 3462,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3463,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3464,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3465,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3466,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3467,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3468,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3469,
      "steps": 96,
      "reward": -138.0
    },
    {
      "episode": 3470,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3471,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3472,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3473,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3474,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3475,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3476,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3477,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3478,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3479,
      "steps": 69,
      "reward": -66.0
    },
    {
      "episode": 3480,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3481,
      "steps": 158,
      "reward": -164.0
    },
    {
      "episode": 3482,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3483,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3484,
      "steps": 67,
      "reward": -145.0
    },
    {
      "episode": 3485,
      "steps": 161,
      "reward": -194.0
    },
    {
      "episode": 3486,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3487,
      "steps": 84,
      "reward": -72.0
    },
    {
      "episode": 3488,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3489,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3490,
      "steps": 93,
      "reward": -81.0
    },
    {
      "episode": 3491,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3492,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3493,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3494,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3495,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3496,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3497,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3498,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3499,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3500,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3501,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3502,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3503,
      "steps": 89,
      "reward": -104.0
    },
    {
      "episode": 3504,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3505,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3506,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3507,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3508,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3509,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3510,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3511,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3512,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3513,
      "steps": 195,
      "reward": -300.0
    },
    {
      "episode": 3514,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3515,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3516,
      "steps": 155,
      "reward": -170.0
    },
    {
      "episode": 3517,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3518,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3519,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3520,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3521,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3522,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3523,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3524,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 3525,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3526,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3527,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3528,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3529,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3530,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3531,
      "steps": 193,
      "reward": -244.0
    },
    {
      "episode": 3532,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3533,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3534,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3535,
      "steps": 188,
      "reward": -257.0
    },
    {
      "episode": 3536,
      "steps": 188,
      "reward": -239.0
    },
    {
      "episode": 3537,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3538,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3539,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3540,
      "steps": 58,
      "reward": -55.0
    },
    {
      "episode": 3541,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3542,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3543,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3544,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3545,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3546,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3547,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3548,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3549,
      "steps": 50,
      "reward": -38.0
    },
    {
      "episode": 3550,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3551,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3552,
      "steps": 42,
      "reward": -21.0
    },
    {
      "episode": 3553,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3554,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3555,
      "steps": 79,
      "reward": -85.0
    },
    {
      "episode": 3556,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3557,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3558,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3559,
      "steps": 124,
      "reward": -157.0
    },
    {
      "episode": 3560,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3561,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3562,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3563,
      "steps": 123,
      "reward": -138.0
    },
    {
      "episode": 3564,
      "steps": 72,
      "reward": -87.0
    },
    {
      "episode": 3565,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3566,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3567,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3568,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3569,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3570,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3571,
      "steps": 171,
      "reward": -213.0
    },
    {
      "episode": 3572,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 3573,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3574,
      "steps": 169,
      "reward": -229.0
    },
    {
      "episode": 3575,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3576,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3577,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3578,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3579,
      "steps": 164,
      "reward": -197.0
    },
    {
      "episode": 3580,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3581,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3582,
      "steps": 75,
      "reward": -72.0
    },
    {
      "episode": 3583,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3584,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3585,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3586,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3587,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3588,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3589,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3590,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3591,
      "steps": 85,
      "reward": -118.0
    },
    {
      "episode": 3592,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3593,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3594,
      "steps": 97,
      "reward": -130.0
    },
    {
      "episode": 3595,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3596,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3597,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3598,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3599,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3600,
      "steps": 133,
      "reward": -175.0
    },
    {
      "episode": 3601,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3602,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3603,
      "steps": 71,
      "reward": -104.0
    },
    {
      "episode": 3604,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3605,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3606,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3607,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3608,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3609,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3610,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3611,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3612,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3613,
      "steps": 54,
      "reward": -51.0
    },
    {
      "episode": 3614,
      "steps": 51,
      "reward": -48.0
    },
    {
      "episode": 3615,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3616,
      "steps": 115,
      "reward": -175.0
    },
    {
      "episode": 3617,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3618,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3619,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3620,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3621,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3622,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3623,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3624,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 3625,
      "steps": 189,
      "reward": -258.0
    },
    {
      "episode": 3626,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3627,
      "steps": 148,
      "reward": -190.0
    },
    {
      "episode": 3628,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3629,
      "steps": 49,
      "reward": -64.0
    },
    {
      "episode": 3630,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3631,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3632,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3633,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3634,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3635,
      "steps": 188,
      "reward": -248.0
    },
    {
      "episode": 3636,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3637,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3638,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3639,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3640,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3641,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3642,
      "steps": 84,
      "reward": -99.0
    },
    {
      "episode": 3643,
      "steps": 88,
      "reward": -112.0
    },
    {
      "episode": 3644,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3645,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3646,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3647,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3648,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3649,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3650,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3651,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3652,
      "steps": 190,
      "reward": -223.0
    },
    {
      "episode": 3653,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3654,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3655,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3656,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3657,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3658,
      "steps": 45,
      "reward": -51.0
    },
    {
      "episode": 3659,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3660,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3661,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3662,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 3663,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3664,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3665,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3666,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3667,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3668,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3669,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3670,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3671,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3672,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3673,
      "steps": 156,
      "reward": -216.0
    },
    {
      "episode": 3674,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3675,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3676,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3677,
      "steps": 137,
      "reward": -188.0
    },
    {
      "episode": 3678,
      "steps": 46,
      "reward": -34.0
    },
    {
      "episode": 3679,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3680,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3681,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3682,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3683,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3684,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3685,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3686,
      "steps": 43,
      "reward": -49.0
    },
    {
      "episode": 3687,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3688,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3689,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3690,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3691,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3692,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3693,
      "steps": 82,
      "reward": -61.0
    },
    {
      "episode": 3694,
      "steps": 115,
      "reward": -121.0
    },
    {
      "episode": 3695,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3696,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3697,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3698,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3699,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3700,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3701,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3702,
      "steps": 116,
      "reward": -131.0
    },
    {
      "episode": 3703,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3704,
      "steps": 127,
      "reward": -151.0
    },
    {
      "episode": 3705,
      "steps": 177,
      "reward": -210.0
    },
    {
      "episode": 3706,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3707,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3708,
      "steps": 28,
      "reward": -16.0
    },
    {
      "episode": 3709,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3710,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3711,
      "steps": 136,
      "reward": -142.0
    },
    {
      "episode": 3712,
      "steps": 69,
      "reward": -84.0
    },
    {
      "episode": 3713,
      "steps": 132,
      "reward": -165.0
    },
    {
      "episode": 3714,
      "steps": 159,
      "reward": -273.0
    },
    {
      "episode": 3715,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3716,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3717,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3718,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3719,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3720,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3721,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3722,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3723,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3724,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3725,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3726,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3727,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3728,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3729,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3730,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3731,
      "steps": 162,
      "reward": -204.0
    },
    {
      "episode": 3732,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3733,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3734,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3735,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3736,
      "steps": 195,
      "reward": -237.0
    },
    {
      "episode": 3737,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3738,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3739,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3740,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3741,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3742,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3743,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3744,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3745,
      "steps": 71,
      "reward": -77.0
    },
    {
      "episode": 3746,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3747,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3748,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3749,
      "steps": 161,
      "reward": -185.0
    },
    {
      "episode": 3750,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3751,
      "steps": 36,
      "reward": -15.0
    },
    {
      "episode": 3752,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3753,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 3754,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3755,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3756,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3757,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3758,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3759,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3760,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3761,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3762,
      "steps": 116,
      "reward": -140.0
    },
    {
      "episode": 3763,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3764,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3765,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3766,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3767,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3768,
      "steps": 198,
      "reward": -267.0
    },
    {
      "episode": 3769,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3770,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3771,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3772,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3773,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3774,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3775,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3776,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3777,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3778,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3779,
      "steps": 105,
      "reward": -129.0
    },
    {
      "episode": 3780,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3781,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3782,
      "steps": 142,
      "reward": -157.0
    },
    {
      "episode": 3783,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3784,
      "steps": 166,
      "reward": -235.0
    },
    {
      "episode": 3785,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3786,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3787,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3788,
      "steps": 137,
      "reward": -134.0
    },
    {
      "episode": 3789,
      "steps": 101,
      "reward": -116.0
    },
    {
      "episode": 3790,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3791,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3792,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3793,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3794,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3795,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3796,
      "steps": 184,
      "reward": -253.0
    },
    {
      "episode": 3797,
      "steps": 200,
      "reward": -251.0
    },
    {
      "episode": 3798,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3799,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3800,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 3801,
      "steps": 151,
      "reward": -148.0
    },
    {
      "episode": 3802,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3803,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3804,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3805,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3806,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3807,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3808,
      "steps": 193,
      "reward": -271.0
    },
    {
      "episode": 3809,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3810,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3811,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3812,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3813,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3814,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3815,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3816,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3817,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3818,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3819,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3820,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 3821,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3822,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3823,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3824,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3825,
      "steps": 132,
      "reward": -129.0
    },
    {
      "episode": 3826,
      "steps": 176,
      "reward": -254.0
    },
    {
      "episode": 3827,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3828,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3829,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3830,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3831,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3832,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3833,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 3834,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3835,
      "steps": 112,
      "reward": -118.0
    },
    {
      "episode": 3836,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3837,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3838,
      "steps": 176,
      "reward": -236.0
    },
    {
      "episode": 3839,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3840,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3841,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3842,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 3843,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3844,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3845,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3846,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3847,
      "steps": 56,
      "reward": -44.0
    },
    {
      "episode": 3848,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3849,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3850,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3851,
      "steps": 172,
      "reward": -250.0
    },
    {
      "episode": 3852,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3853,
      "steps": 164,
      "reward": -242.0
    },
    {
      "episode": 3854,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3855,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3856,
      "steps": 139,
      "reward": -163.0
    },
    {
      "episode": 3857,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3858,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3859,
      "steps": 121,
      "reward": -145.0
    },
    {
      "episode": 3860,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3861,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3862,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3863,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3864,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3865,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3866,
      "steps": 173,
      "reward": -260.0
    },
    {
      "episode": 3867,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3868,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3869,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3870,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3871,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3872,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3873,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3874,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3875,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3876,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3877,
      "steps": 177,
      "reward": -210.0
    },
    {
      "episode": 3878,
      "steps": 111,
      "reward": -144.0
    },
    {
      "episode": 3879,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3880,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3881,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3882,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3883,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3884,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3885,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3886,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3887,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3888,
      "steps": 53,
      "reward": -50.0
    },
    {
      "episode": 3889,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3890,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3891,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3892,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3893,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3894,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3895,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3896,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3897,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3898,
      "steps": 61,
      "reward": -67.0
    },
    {
      "episode": 3899,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3900,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3901,
      "steps": 168,
      "reward": -219.0
    },
    {
      "episode": 3902,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3903,
      "steps": 110,
      "reward": -125.0
    },
    {
      "episode": 3904,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3905,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3906,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3907,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3908,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 3909,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3910,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3911,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3912,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3913,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3914,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3915,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3916,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3917,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3918,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3919,
      "steps": 50,
      "reward": -65.0
    },
    {
      "episode": 3920,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3921,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3922,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3923,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3924,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3925,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3926,
      "steps": 138,
      "reward": -162.0
    },
    {
      "episode": 3927,
      "steps": 72,
      "reward": -69.0
    },
    {
      "episode": 3928,
      "steps": 99,
      "reward": -123.0
    },
    {
      "episode": 3929,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3930,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3931,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3932,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3933,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3934,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3935,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3936,
      "steps": 196,
      "reward": -274.0
    },
    {
      "episode": 3937,
      "steps": 72,
      "reward": -69.0
    },
    {
      "episode": 3938,
      "steps": 34,
      "reward": -13.0
    },
    {
      "episode": 3939,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3940,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3941,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3942,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3943,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3944,
      "steps": 149,
      "reward": -200.0
    },
    {
      "episode": 3945,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3946,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3947,
      "steps": 149,
      "reward": -191.0
    },
    {
      "episode": 3948,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3949,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3950,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3951,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3952,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3953,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3954,
      "steps": 87,
      "reward": -120.0
    },
    {
      "episode": 3955,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3956,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3957,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3958,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3959,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3960,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3961,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3962,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3963,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3964,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 3965,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3966,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3967,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3968,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3969,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 3970,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3971,
      "steps": 168,
      "reward": -219.0
    },
    {
      "episode": 3972,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3973,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3974,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3975,
      "steps": 117,
      "reward": -168.0
    },
    {
      "episode": 3976,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 3977,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3978,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3979,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3980,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3981,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3982,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3983,
      "steps": 171,
      "reward": -231.0
    },
    {
      "episode": 3984,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 3985,
      "steps": 42,
      "reward": -21.0
    },
    {
      "episode": 3986,
      "steps": 29,
      "reward": -8.0
    },
    {
      "episode": 3987,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 3988,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3989,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 3990,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3991,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 3992,
      "steps": 140,
      "reward": -191.0
    },
    {
      "episode": 3993,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 3994,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3995,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 3996,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 3997,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3998,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 3999,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4000,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4001,
      "steps": 172,
      "reward": -223.0
    },
    {
      "episode": 4002,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4003,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4004,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4005,
      "steps": 137,
      "reward": -143.0
    },
    {
      "episode": 4006,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4007,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4008,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4009,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4010,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4011,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4012,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4013,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4014,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4015,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4016,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4017,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4018,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4019,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4020,
      "steps": 150,
      "reward": -156.0
    },
    {
      "episode": 4021,
      "steps": 116,
      "reward": -149.0
    },
    {
      "episode": 4022,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4023,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4024,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4025,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4026,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4027,
      "steps": 167,
      "reward": -182.0
    },
    {
      "episode": 4028,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4029,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4030,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4031,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4032,
      "steps": 26,
      "reward": -5.0
    },
    {
      "episode": 4033,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4034,
      "steps": 84,
      "reward": -126.0
    },
    {
      "episode": 4035,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4036,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4037,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4038,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4039,
      "steps": 73,
      "reward": -70.0
    },
    {
      "episode": 4040,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4041,
      "steps": 48,
      "reward": -27.0
    },
    {
      "episode": 4042,
      "steps": 161,
      "reward": -185.0
    },
    {
      "episode": 4043,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4044,
      "steps": 185,
      "reward": -245.0
    },
    {
      "episode": 4045,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4046,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4047,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4048,
      "steps": 129,
      "reward": -171.0
    },
    {
      "episode": 4049,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4050,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4051,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4052,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4053,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4054,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4055,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4056,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4057,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4058,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4059,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4060,
      "steps": 132,
      "reward": -165.0
    },
    {
      "episode": 4061,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4062,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4063,
      "steps": 78,
      "reward": -84.0
    },
    {
      "episode": 4064,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4065,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4066,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4067,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 4068,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4069,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4070,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4071,
      "steps": 57,
      "reward": -72.0
    },
    {
      "episode": 4072,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4073,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4074,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4075,
      "steps": 104,
      "reward": -119.0
    },
    {
      "episode": 4076,
      "steps": 33,
      "reward": -21.0
    },
    {
      "episode": 4077,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4078,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4079,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4080,
      "steps": 97,
      "reward": -112.0
    },
    {
      "episode": 4081,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4082,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4083,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4084,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4085,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4086,
      "steps": 157,
      "reward": -136.0
    },
    {
      "episode": 4087,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4088,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4089,
      "steps": 148,
      "reward": -172.0
    },
    {
      "episode": 4090,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4091,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4092,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4093,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4094,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4095,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4096,
      "steps": 198,
      "reward": -294.0
    },
    {
      "episode": 4097,
      "steps": 139,
      "reward": -136.0
    },
    {
      "episode": 4098,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4099,
      "steps": 144,
      "reward": -141.0
    },
    {
      "episode": 4100,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4101,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4102,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4103,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4104,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4105,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4106,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4107,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4108,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4109,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4110,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4111,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4112,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4113,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4114,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4115,
      "steps": 156,
      "reward": -207.0
    },
    {
      "episode": 4116,
      "steps": 137,
      "reward": -170.0
    },
    {
      "episode": 4117,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4118,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4119,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4120,
      "steps": 61,
      "reward": -67.0
    },
    {
      "episode": 4121,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4122,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4123,
      "steps": 79,
      "reward": -76.0
    },
    {
      "episode": 4124,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4125,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4126,
      "steps": 196,
      "reward": -238.0
    },
    {
      "episode": 4127,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4128,
      "steps": 179,
      "reward": -239.0
    },
    {
      "episode": 4129,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4130,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4131,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4132,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4133,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4134,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 4135,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4136,
      "steps": 177,
      "reward": -237.0
    },
    {
      "episode": 4137,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4138,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4139,
      "steps": 55,
      "reward": -34.0
    },
    {
      "episode": 4140,
      "steps": 189,
      "reward": -249.0
    },
    {
      "episode": 4141,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4142,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4143,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4144,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4145,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4146,
      "steps": 175,
      "reward": -217.0
    },
    {
      "episode": 4147,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4148,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4149,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4150,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 4151,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4152,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4153,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4154,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4155,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4156,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4157,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4158,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4159,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4160,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4161,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4162,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4163,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4164,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4165,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4166,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4167,
      "steps": 85,
      "reward": -118.0
    },
    {
      "episode": 4168,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4169,
      "steps": 68,
      "reward": -47.0
    },
    {
      "episode": 4170,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4171,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4172,
      "steps": 156,
      "reward": -207.0
    },
    {
      "episode": 4173,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4174,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4175,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4176,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4177,
      "steps": 121,
      "reward": -154.0
    },
    {
      "episode": 4178,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4179,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4180,
      "steps": 47,
      "reward": -44.0
    },
    {
      "episode": 4181,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4182,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4183,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4184,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4185,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4186,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4187,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4188,
      "steps": 48,
      "reward": -45.0
    },
    {
      "episode": 4189,
      "steps": 183,
      "reward": -225.0
    },
    {
      "episode": 4190,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4191,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4192,
      "steps": 199,
      "reward": -259.0
    },
    {
      "episode": 4193,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4194,
      "steps": 115,
      "reward": -112.0
    },
    {
      "episode": 4195,
      "steps": 169,
      "reward": -202.0
    },
    {
      "episode": 4196,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4197,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4198,
      "steps": 170,
      "reward": -185.0
    },
    {
      "episode": 4199,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 4200,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4201,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4202,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4203,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4204,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4205,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4206,
      "steps": 162,
      "reward": -222.0
    },
    {
      "episode": 4207,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4208,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4209,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 4210,
      "steps": 47,
      "reward": -62.0
    },
    {
      "episode": 4211,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4212,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4213,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4214,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4215,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4216,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4217,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4218,
      "steps": 169,
      "reward": -229.0
    },
    {
      "episode": 4219,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4220,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4221,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4222,
      "steps": 165,
      "reward": -225.0
    },
    {
      "episode": 4223,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4224,
      "steps": 87,
      "reward": -102.0
    },
    {
      "episode": 4225,
      "steps": 200,
      "reward": -371.0
    },
    {
      "episode": 4226,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4227,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4228,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4229,
      "steps": 192,
      "reward": -252.0
    },
    {
      "episode": 4230,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4231,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4232,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4233,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4234,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4235,
      "steps": 68,
      "reward": -65.0
    },
    {
      "episode": 4236,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4237,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4238,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4239,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4240,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4241,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4242,
      "steps": 67,
      "reward": -91.0
    },
    {
      "episode": 4243,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4244,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4245,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4246,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4247,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4248,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4249,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4250,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4251,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4252,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 4253,
      "steps": 129,
      "reward": -162.0
    },
    {
      "episode": 4254,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4255,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4256,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4257,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4258,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4259,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4260,
      "steps": 83,
      "reward": -80.0
    },
    {
      "episode": 4261,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4262,
      "steps": 40,
      "reward": -37.0
    },
    {
      "episode": 4263,
      "steps": 194,
      "reward": -218.0
    },
    {
      "episode": 4264,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4265,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4266,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4267,
      "steps": 120,
      "reward": -135.0
    },
    {
      "episode": 4268,
      "steps": 196,
      "reward": -265.0
    },
    {
      "episode": 4269,
      "steps": 51,
      "reward": -48.0
    },
    {
      "episode": 4270,
      "steps": 116,
      "reward": -122.0
    },
    {
      "episode": 4271,
      "steps": 86,
      "reward": -65.0
    },
    {
      "episode": 4272,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4273,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4274,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4275,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4276,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4277,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4278,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4279,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4280,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4281,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4282,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4283,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4284,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4285,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4286,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4287,
      "steps": 47,
      "reward": -35.0
    },
    {
      "episode": 4288,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4289,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4290,
      "steps": 182,
      "reward": -242.0
    },
    {
      "episode": 4291,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4292,
      "steps": 136,
      "reward": -133.0
    },
    {
      "episode": 4293,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4294,
      "steps": 17,
      "reward": -5.0
    },
    {
      "episode": 4295,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4296,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4297,
      "steps": 72,
      "reward": -69.0
    },
    {
      "episode": 4298,
      "steps": 167,
      "reward": -182.0
    },
    {
      "episode": 4299,
      "steps": 112,
      "reward": -163.0
    },
    {
      "episode": 4300,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4301,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4302,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 4303,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4304,
      "steps": 64,
      "reward": -88.0
    },
    {
      "episode": 4305,
      "steps": 107,
      "reward": -149.0
    },
    {
      "episode": 4306,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4307,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4308,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4309,
      "steps": 127,
      "reward": -187.0
    },
    {
      "episode": 4310,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4311,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4312,
      "steps": 167,
      "reward": -209.0
    },
    {
      "episode": 4313,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4314,
      "steps": 173,
      "reward": -215.0
    },
    {
      "episode": 4315,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4316,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4317,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4318,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4319,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4320,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 4321,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4322,
      "steps": 129,
      "reward": -126.0
    },
    {
      "episode": 4323,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4324,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4325,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4326,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4327,
      "steps": 103,
      "reward": -109.0
    },
    {
      "episode": 4328,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4329,
      "steps": 173,
      "reward": -215.0
    },
    {
      "episode": 4330,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4331,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4332,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4333,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4334,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4335,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4336,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 4337,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4338,
      "steps": 76,
      "reward": -73.0
    },
    {
      "episode": 4339,
      "steps": 129,
      "reward": -189.0
    },
    {
      "episode": 4340,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4341,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4342,
      "steps": 144,
      "reward": -132.0
    },
    {
      "episode": 4343,
      "steps": 109,
      "reward": -124.0
    },
    {
      "episode": 4344,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4345,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4346,
      "steps": 109,
      "reward": -106.0
    },
    {
      "episode": 4347,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4348,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4349,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4350,
      "steps": 126,
      "reward": -195.0
    },
    {
      "episode": 4351,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4352,
      "steps": 193,
      "reward": -244.0
    },
    {
      "episode": 4353,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4354,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4355,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 4356,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4357,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4358,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4359,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 4360,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4361,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4362,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4363,
      "steps": 116,
      "reward": -158.0
    },
    {
      "episode": 4364,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4365,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4366,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4367,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4368,
      "steps": 63,
      "reward": -42.0
    },
    {
      "episode": 4369,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4370,
      "steps": 71,
      "reward": -68.0
    },
    {
      "episode": 4371,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4372,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4373,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4374,
      "steps": 186,
      "reward": -282.0
    },
    {
      "episode": 4375,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4376,
      "steps": 70,
      "reward": -67.0
    },
    {
      "episode": 4377,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4378,
      "steps": 143,
      "reward": -167.0
    },
    {
      "episode": 4379,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4380,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4381,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4382,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 4383,
      "steps": 100,
      "reward": -115.0
    },
    {
      "episode": 4384,
      "steps": 70,
      "reward": -49.0
    },
    {
      "episode": 4385,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4386,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4387,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4388,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4389,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4390,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4391,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4392,
      "steps": 140,
      "reward": -173.0
    },
    {
      "episode": 4393,
      "steps": 42,
      "reward": -57.0
    },
    {
      "episode": 4394,
      "steps": 176,
      "reward": -236.0
    },
    {
      "episode": 4395,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4396,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4397,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4398,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4399,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4400,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4401,
      "steps": 191,
      "reward": -305.0
    },
    {
      "episode": 4402,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4403,
      "steps": 156,
      "reward": -171.0
    },
    {
      "episode": 4404,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4405,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4406,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4407,
      "steps": 136,
      "reward": -133.0
    },
    {
      "episode": 4408,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4409,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4410,
      "steps": 166,
      "reward": -172.0
    },
    {
      "episode": 4411,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4412,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4413,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 4414,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4415,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4416,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4417,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4418,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4419,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4420,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4421,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4422,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4423,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4424,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4425,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4426,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4427,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4428,
      "steps": 52,
      "reward": -40.0
    },
    {
      "episode": 4429,
      "steps": 127,
      "reward": -187.0
    },
    {
      "episode": 4430,
      "steps": 111,
      "reward": -126.0
    },
    {
      "episode": 4431,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4432,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4433,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4434,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4435,
      "steps": 73,
      "reward": -79.0
    },
    {
      "episode": 4436,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4437,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 4438,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4439,
      "steps": 84,
      "reward": -117.0
    },
    {
      "episode": 4440,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 4441,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 4442,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4443,
      "steps": 171,
      "reward": -222.0
    },
    {
      "episode": 4444,
      "steps": 140,
      "reward": -200.0
    },
    {
      "episode": 4445,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4446,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4447,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4448,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4449,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4450,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4451,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4452,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4453,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4454,
      "steps": 61,
      "reward": -76.0
    },
    {
      "episode": 4455,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 4456,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4457,
      "steps": 162,
      "reward": -213.0
    },
    {
      "episode": 4458,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4459,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4460,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4461,
      "steps": 162,
      "reward": -204.0
    },
    {
      "episode": 4462,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4463,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4464,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4465,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4466,
      "steps": 52,
      "reward": -58.0
    },
    {
      "episode": 4467,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4468,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 4469,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4470,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4471,
      "steps": 62,
      "reward": -59.0
    },
    {
      "episode": 4472,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4473,
      "steps": 91,
      "reward": -88.0
    },
    {
      "episode": 4474,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4475,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4476,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4477,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4478,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4479,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4480,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4481,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4482,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 4483,
      "steps": 102,
      "reward": -135.0
    },
    {
      "episode": 4484,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4485,
      "steps": 140,
      "reward": -146.0
    },
    {
      "episode": 4486,
      "steps": 120,
      "reward": -135.0
    },
    {
      "episode": 4487,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4488,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4489,
      "steps": 176,
      "reward": -236.0
    },
    {
      "episode": 4490,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4491,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4492,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4493,
      "steps": 39,
      "reward": -27.0
    },
    {
      "episode": 4494,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4495,
      "steps": 110,
      "reward": -134.0
    },
    {
      "episode": 4496,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4497,
      "steps": 49,
      "reward": -91.0
    },
    {
      "episode": 4498,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 4499,
      "steps": 174,
      "reward": -252.0
    },
    {
      "episode": 4500,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4501,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4502,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4503,
      "steps": 21,
      "reward": -18.0
    },
    {
      "episode": 4504,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4505,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4506,
      "steps": 143,
      "reward": -158.0
    },
    {
      "episode": 4507,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4508,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4509,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4510,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4511,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4512,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4513,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4514,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4515,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4516,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4517,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4518,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4519,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4520,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4521,
      "steps": 139,
      "reward": -208.0
    },
    {
      "episode": 4522,
      "steps": 63,
      "reward": -78.0
    },
    {
      "episode": 4523,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4524,
      "steps": 123,
      "reward": -138.0
    },
    {
      "episode": 4525,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4526,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4527,
      "steps": 149,
      "reward": -218.0
    },
    {
      "episode": 4528,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4529,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4530,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4531,
      "steps": 103,
      "reward": -154.0
    },
    {
      "episode": 4532,
      "steps": 158,
      "reward": -200.0
    },
    {
      "episode": 4533,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4534,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4535,
      "steps": 170,
      "reward": -248.0
    },
    {
      "episode": 4536,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4537,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4538,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4539,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4540,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4541,
      "steps": 194,
      "reward": -272.0
    },
    {
      "episode": 4542,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4543,
      "steps": 194,
      "reward": -209.0
    },
    {
      "episode": 4544,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4545,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4546,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4547,
      "steps": 73,
      "reward": -70.0
    },
    {
      "episode": 4548,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4549,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4550,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4551,
      "steps": 36,
      "reward": -15.0
    },
    {
      "episode": 4552,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4553,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4554,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4555,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4556,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4557,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4558,
      "steps": 52,
      "reward": -31.0
    },
    {
      "episode": 4559,
      "steps": 166,
      "reward": -190.0
    },
    {
      "episode": 4560,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4561,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4562,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 4563,
      "steps": 72,
      "reward": -87.0
    },
    {
      "episode": 4564,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4565,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4566,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4567,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4568,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4569,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4570,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4571,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4572,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4573,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4574,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4575,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4576,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4577,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4578,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4579,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4580,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4581,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4582,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4583,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4584,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4585,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4586,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4587,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4588,
      "steps": 31,
      "reward": -10.0
    },
    {
      "episode": 4589,
      "steps": 57,
      "reward": -63.0
    },
    {
      "episode": 4590,
      "steps": 141,
      "reward": -183.0
    },
    {
      "episode": 4591,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4592,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4593,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4594,
      "steps": 138,
      "reward": -153.0
    },
    {
      "episode": 4595,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4596,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 4597,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4598,
      "steps": 161,
      "reward": -221.0
    },
    {
      "episode": 4599,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4600,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4601,
      "steps": 170,
      "reward": -275.0
    },
    {
      "episode": 4602,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4603,
      "steps": 127,
      "reward": -124.0
    },
    {
      "episode": 4604,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4605,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4606,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4607,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4608,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4609,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4610,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4611,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4612,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4613,
      "steps": 174,
      "reward": -261.0
    },
    {
      "episode": 4614,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4615,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4616,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4617,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4618,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4619,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4620,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4621,
      "steps": 125,
      "reward": -158.0
    },
    {
      "episode": 4622,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4623,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 4624,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 4625,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4626,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4627,
      "steps": 138,
      "reward": -216.0
    },
    {
      "episode": 4628,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4629,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4630,
      "steps": 72,
      "reward": -78.0
    },
    {
      "episode": 4631,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4632,
      "steps": 198,
      "reward": -240.0
    },
    {
      "episode": 4633,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4634,
      "steps": 19,
      "reward": -7.0
    },
    {
      "episode": 4635,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4636,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4637,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4638,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4639,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4640,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4641,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4642,
      "steps": 131,
      "reward": -164.0
    },
    {
      "episode": 4643,
      "steps": 18,
      "reward": 3.0
    },
    {
      "episode": 4644,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4645,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4646,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4647,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4648,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4649,
      "steps": 181,
      "reward": -196.0
    },
    {
      "episode": 4650,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4651,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4652,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4653,
      "steps": 61,
      "reward": -67.0
    },
    {
      "episode": 4654,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4655,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4656,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4657,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4658,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4659,
      "steps": 83,
      "reward": -71.0
    },
    {
      "episode": 4660,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4661,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4662,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4663,
      "steps": 167,
      "reward": -164.0
    },
    {
      "episode": 4664,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4665,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4666,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4667,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4668,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4669,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4670,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4671,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4672,
      "steps": 124,
      "reward": -148.0
    },
    {
      "episode": 4673,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4674,
      "steps": 154,
      "reward": -205.0
    },
    {
      "episode": 4675,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4676,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 4677,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4678,
      "steps": 132,
      "reward": -147.0
    },
    {
      "episode": 4679,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4680,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4681,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4682,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4683,
      "steps": 113,
      "reward": -137.0
    },
    {
      "episode": 4684,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4685,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4686,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4687,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 4688,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4689,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4690,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4691,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4692,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4693,
      "steps": 150,
      "reward": -174.0
    },
    {
      "episode": 4694,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4695,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4696,
      "steps": 30,
      "reward": -18.0
    },
    {
      "episode": 4697,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4698,
      "steps": 173,
      "reward": -206.0
    },
    {
      "episode": 4699,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4700,
      "steps": 130,
      "reward": -154.0
    },
    {
      "episode": 4701,
      "steps": 140,
      "reward": -164.0
    },
    {
      "episode": 4702,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 4703,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4704,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 4705,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4706,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4707,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4708,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4709,
      "steps": 27,
      "reward": -15.0
    },
    {
      "episode": 4710,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4711,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4712,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4713,
      "steps": 187,
      "reward": -238.0
    },
    {
      "episode": 4714,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4715,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4716,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4717,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4718,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4719,
      "steps": 123,
      "reward": -174.0
    },
    {
      "episode": 4720,
      "steps": 118,
      "reward": -133.0
    },
    {
      "episode": 4721,
      "steps": 40,
      "reward": -28.0
    },
    {
      "episode": 4722,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4723,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4724,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4725,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4726,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4727,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4728,
      "steps": 152,
      "reward": -203.0
    },
    {
      "episode": 4729,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4730,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4731,
      "steps": 31,
      "reward": -28.0
    },
    {
      "episode": 4732,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4733,
      "steps": 106,
      "reward": -130.0
    },
    {
      "episode": 4734,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4735,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 4736,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4737,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4738,
      "steps": 186,
      "reward": -273.0
    },
    {
      "episode": 4739,
      "steps": 115,
      "reward": -148.0
    },
    {
      "episode": 4740,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4741,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4742,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4743,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4744,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4745,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4746,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4747,
      "steps": 181,
      "reward": -223.0
    },
    {
      "episode": 4748,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4749,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4750,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4751,
      "steps": 167,
      "reward": -173.0
    },
    {
      "episode": 4752,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4753,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4754,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4755,
      "steps": 198,
      "reward": -213.0
    },
    {
      "episode": 4756,
      "steps": 151,
      "reward": -229.0
    },
    {
      "episode": 4757,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4758,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4759,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4760,
      "steps": 123,
      "reward": -102.0
    },
    {
      "episode": 4761,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4762,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4763,
      "steps": 181,
      "reward": -232.0
    },
    {
      "episode": 4764,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4765,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4766,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4767,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4768,
      "steps": 192,
      "reward": -189.0
    },
    {
      "episode": 4769,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4770,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4771,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4772,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 4773,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4774,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4775,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4776,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4777,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4778,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4779,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4780,
      "steps": 25,
      "reward": -22.0
    },
    {
      "episode": 4781,
      "steps": 105,
      "reward": -138.0
    },
    {
      "episode": 4782,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4783,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4784,
      "steps": 172,
      "reward": -241.0
    },
    {
      "episode": 4785,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4786,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4787,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4788,
      "steps": 155,
      "reward": -197.0
    },
    {
      "episode": 4789,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4790,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4791,
      "steps": 41,
      "reward": -29.0
    },
    {
      "episode": 4792,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4793,
      "steps": 130,
      "reward": -154.0
    },
    {
      "episode": 4794,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4795,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4796,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4797,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4798,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 4799,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 4800,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4801,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4802,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4803,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4804,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4805,
      "steps": 54,
      "reward": -60.0
    },
    {
      "episode": 4806,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4807,
      "steps": 98,
      "reward": -131.0
    },
    {
      "episode": 4808,
      "steps": 42,
      "reward": -30.0
    },
    {
      "episode": 4809,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4810,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4811,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4812,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4813,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4814,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4815,
      "steps": 179,
      "reward": -221.0
    },
    {
      "episode": 4816,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4817,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4818,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4819,
      "steps": 105,
      "reward": -120.0
    },
    {
      "episode": 4820,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4821,
      "steps": 53,
      "reward": -41.0
    },
    {
      "episode": 4822,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4823,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4824,
      "steps": 136,
      "reward": -178.0
    },
    {
      "episode": 4825,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4826,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4827,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4828,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4829,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4830,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4831,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4832,
      "steps": 92,
      "reward": -98.0
    },
    {
      "episode": 4833,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4834,
      "steps": 196,
      "reward": -229.0
    },
    {
      "episode": 4835,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4836,
      "steps": 61,
      "reward": -58.0
    },
    {
      "episode": 4837,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4838,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4839,
      "steps": 98,
      "reward": -95.0
    },
    {
      "episode": 4840,
      "steps": 106,
      "reward": -139.0
    },
    {
      "episode": 4841,
      "steps": 174,
      "reward": -198.0
    },
    {
      "episode": 4842,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4843,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4844,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4845,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4846,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4847,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4848,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4849,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4850,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4851,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4852,
      "steps": 26,
      "reward": -14.0
    },
    {
      "episode": 4853,
      "steps": 124,
      "reward": -157.0
    },
    {
      "episode": 4854,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4855,
      "steps": 172,
      "reward": -187.0
    },
    {
      "episode": 4856,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4857,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4858,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4859,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4860,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4861,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4862,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4863,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4864,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4865,
      "steps": 113,
      "reward": -146.0
    },
    {
      "episode": 4866,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 4867,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4868,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4869,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 4870,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4871,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4872,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 4873,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4874,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4875,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4876,
      "steps": 93,
      "reward": -108.0
    },
    {
      "episode": 4877,
      "steps": 124,
      "reward": -148.0
    },
    {
      "episode": 4878,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4879,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4880,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4881,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4882,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4883,
      "steps": 99,
      "reward": -105.0
    },
    {
      "episode": 4884,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4885,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4886,
      "steps": 172,
      "reward": -214.0
    },
    {
      "episode": 4887,
      "steps": 200,
      "reward": -326.0
    },
    {
      "episode": 4888,
      "steps": 176,
      "reward": -218.0
    },
    {
      "episode": 4889,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4890,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4891,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4892,
      "steps": 128,
      "reward": -179.0
    },
    {
      "episode": 4893,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4894,
      "steps": 156,
      "reward": -207.0
    },
    {
      "episode": 4895,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4896,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 4897,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4898,
      "steps": 16,
      "reward": 5.0
    },
    {
      "episode": 4899,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4900,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4901,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4902,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4903,
      "steps": 194,
      "reward": -227.0
    },
    {
      "episode": 4904,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4905,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4906,
      "steps": 200,
      "reward": -335.0
    },
    {
      "episode": 4907,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4908,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4909,
      "steps": 200,
      "reward": -227.0
    },
    {
      "episode": 4910,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4911,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4912,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4913,
      "steps": 66,
      "reward": -81.0
    },
    {
      "episode": 4914,
      "steps": 103,
      "reward": -118.0
    },
    {
      "episode": 4915,
      "steps": 170,
      "reward": -266.0
    },
    {
      "episode": 4916,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4917,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4918,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4919,
      "steps": 138,
      "reward": -180.0
    },
    {
      "episode": 4920,
      "steps": 123,
      "reward": -129.0
    },
    {
      "episode": 4921,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4922,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4923,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 4924,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 4925,
      "steps": 200,
      "reward": -218.0
    },
    {
      "episode": 4926,
      "steps": 52,
      "reward": -40.0
    },
    {
      "episode": 4927,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4928,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4929,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4930,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4931,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4932,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4933,
      "steps": 191,
      "reward": -251.0
    },
    {
      "episode": 4934,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4935,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4936,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4937,
      "steps": 200,
      "reward": -317.0
    },
    {
      "episode": 4938,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4939,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4940,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4941,
      "steps": 168,
      "reward": -201.0
    },
    {
      "episode": 4942,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 4943,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4944,
      "steps": 139,
      "reward": -154.0
    },
    {
      "episode": 4945,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4946,
      "steps": 200,
      "reward": -308.0
    },
    {
      "episode": 4947,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4948,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4949,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4950,
      "steps": 200,
      "reward": -353.0
    },
    {
      "episode": 4951,
      "steps": 200,
      "reward": -245.0
    },
    {
      "episode": 4952,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4953,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4954,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4955,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4956,
      "steps": 50,
      "reward": -47.0
    },
    {
      "episode": 4957,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4958,
      "steps": 149,
      "reward": -182.0
    },
    {
      "episode": 4959,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4960,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4961,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4962,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4963,
      "steps": 190,
      "reward": -241.0
    },
    {
      "episode": 4964,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4965,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4966,
      "steps": 68,
      "reward": -74.0
    },
    {
      "episode": 4967,
      "steps": 200,
      "reward": -269.0
    },
    {
      "episode": 4968,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4969,
      "steps": 200,
      "reward": -299.0
    },
    {
      "episode": 4970,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4971,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4972,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4973,
      "steps": 164,
      "reward": -215.0
    },
    {
      "episode": 4974,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4975,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4976,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4977,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4978,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4979,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4980,
      "steps": 109,
      "reward": -151.0
    },
    {
      "episode": 4981,
      "steps": 200,
      "reward": -290.0
    },
    {
      "episode": 4982,
      "steps": 200,
      "reward": -236.0
    },
    {
      "episode": 4983,
      "steps": 198,
      "reward": -240.0
    },
    {
      "episode": 4984,
      "steps": 72,
      "reward": -114.0
    },
    {
      "episode": 4985,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4986,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4987,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4988,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4989,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4990,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4991,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4992,
      "steps": 200,
      "reward": -344.0
    },
    {
      "episode": 4993,
      "steps": 200,
      "reward": -281.0
    },
    {
      "episode": 4994,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4995,
      "steps": 200,
      "reward": -263.0
    },
    {
      "episode": 4996,
      "steps": 109,
      "reward": -97.0
    },
    {
      "episode": 4997,
      "steps": 200,
      "reward": -272.0
    },
    {
      "episode": 4998,
      "steps": 200,
      "reward": -254.0
    },
    {
      "episode": 4999,
      "steps": 188,
      "reward": -230.0
    },
    {
      "episode": 5000,
      "steps": 143,
      "reward": -131.0
    }
  ]
}